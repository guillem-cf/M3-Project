{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 1\n",
    "- Guillem\n",
    "- Anna\n",
    "- Johnny"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "● Test different amounts of local features. What performs best?  \n",
    "● Use dense SIFT instead of detected keypoints. Conclusions?  \n",
    "● Test different amounts of codebook sizes k. What performs best?  \n",
    "● Test different values of k for the k-nn classifier. What performs best?  \n",
    "● Test other distances in k-nn classifier. Does that make a difference? Why?  \n",
    "● Play with reducing dimensionality. Conclusions?  \n",
    "● Cross-validate everything (topic covered on Wednesday)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import optuna\n",
    "from optuna.visualization.matplotlib import plot_contour, plot_edf, plot_intermediate_values, plot_optimization_history, plot_parallel_coordinate, plot_param_importances, plot_slice\n",
    "import os\n",
    "from optuna.samplers import TPESampler\n",
    "import concurrent.futures\n",
    "import gc\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read and visualize the train and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filenames = pickle.load(\n",
    "    open('MIT_split/train_images_filenames_unix.dat', 'rb'))\n",
    "test_images_filenames = pickle.load(\n",
    "    open('MIT_split/test_images_filenames_unix.dat', 'rb'))\n",
    "# train_images_filenames = ['..' + n[15:] for n in train_images_filenames] original\n",
    "# test_images_filenames  = ['..' + n[15:] for n in test_images_filenames]  original\n",
    "train_images_filenames = [n[16:] for n in train_images_filenames]\n",
    "test_images_filenames = [n[16:] for n in test_images_filenames]\n",
    "train_labels = pickle.load(open('MIT_split/train_labels_unix.dat', 'rb'))\n",
    "test_labels = pickle.load(open('MIT_split/test_labels_unix.dat', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filenames[12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize images of each class of the dataset\n",
    "def visualize(images_filenames, labels, num_images=5):\n",
    "    print(f'Number of samples: {len(images_filenames)}')\n",
    "    # get unique classses\n",
    "    classes = np.unique(np.array(labels))\n",
    "    num_classes = len(classes)\n",
    "    # set size for plot\n",
    "    plt.figure(figsize=(15,8))\n",
    "    # loop over classes\n",
    "    for i, c in enumerate(classes):\n",
    "        # get the first 5 images of the class\n",
    "        idx = np.where(np.array(labels) == c)[0][:num_images]\n",
    "        # loop over the images and plot them\n",
    "        for j, index in enumerate(idx):\n",
    "            plt_idx = j * num_classes + i + 1\n",
    "            plt.subplot(num_images, num_classes, plt_idx)\n",
    "            plt.imshow(cv2.cvtColor(cv2.imread(images_filenames[index]), cv2.COLOR_BGR2RGB))\n",
    "            plt.axis('off')\n",
    "            if j == 0:\n",
    "                plt.title(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the train dataset\n",
    "visualize(train_images_filenames, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the test dataset\n",
    "visualize(test_images_filenames, test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Distribution Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes, counts = np.unique(train_labels, return_counts=True)\n",
    "total_count = sum(counts)\n",
    "train_class_proportions = counts / total_count\n",
    "\n",
    "# Calculate the class proportions for the test set\n",
    "unique_classes, counts = np.unique(test_labels, return_counts=True)\n",
    "total_count = sum(counts)\n",
    "test_class_proportions = counts / total_count\n",
    "\n",
    "# Print the class proportions for the train and test sets\n",
    "print(\"Train set class proportions:\", train_class_proportions)\n",
    "print(\"Test set class proportions:\", test_class_proportions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = np.unique(train_labels + test_labels)\n",
    "train_count = [np.sum(np.array(train_labels) == lab) for lab in unique_labels]\n",
    "test_count = [np.sum(np.array(test_labels) == lab) for lab in unique_labels]\n",
    "\n",
    "\n",
    "# distribution of the training and test set\n",
    "def plot_distribution(train_count, test_count, unique_labels):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.title(\"Distribution of the training and test set\")\n",
    "    plt.bar(unique_labels, train_count, label=\"Training Set\")\n",
    "    plt.bar(unique_labels, test_count, label=\"Test Set\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_distribution(train_count, test_count, unique_labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: EXPLANATION\n",
    "To check if a dataset is unbalanced, we can calculate the proportion of each class in the dataset and compare the proportions. If the proportions of the classes are significantly different, then the dataset is likely to be unbalanced.\n",
    "In this case, the dataset is balanced"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KAZE:\n",
    "    def __init__(self, threshold=0.001):\n",
    "        self.extractor = cv2.KAZE_create(threshold=threshold)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class AKAZE:\n",
    "    def __init__(self, threshold=0.001):\n",
    "        self.extractor = cv2.AKAZE_create(threshold=threshold)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class SIFT:\n",
    "    def __init__(self, n_features=300):\n",
    "        self.extractor = cv2.SIFT_create(nfeatures=n_features)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class DenseSIFT:\n",
    "    def __init__(self, n_features=300, step_size=10, patch_size=10):\n",
    "        self.extractor = cv2.SIFT_create(nfeatures=n_features)\n",
    "        self.step_div_size = step_size\n",
    "        self.num_sizes = patch_size\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        descriptors = []\n",
    "        init_step_size_x = max(image.shape[1] // self.step_div_size, 16)\n",
    "        init_step_size_y = max(image.shape[0] // self.step_div_size, 16)\n",
    "        \n",
    "        for i in range(1, self.num_sizes+1):\n",
    "            current_step_x = init_step_size_x * i\n",
    "            current_step_y = init_step_size_y * i\n",
    "            avg_size = (current_step_x + current_step_y) // 2\n",
    "            descriptors += [cv2.KeyPoint(x, y, avg_size) for y in range(0, image.shape[0], current_step_y) \n",
    "                                                    for x in range(0, image.shape[1], current_step_x)]\n",
    "        descriptors = self.extractor.compute(image, descriptors)[1]\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class ORB:\n",
    "    def __init__(self, n_features=100):\n",
    "        self.extractor = cv2.ORB_create(nfeatures=n_features)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class BRISK:\n",
    "    def __init__(self, n_features=100):\n",
    "        self.extractor = cv2.BRISK_create(nfeatures=n_features)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractors = {\n",
    "    \"SIFT\": SIFT,\n",
    "    \"DenseSIFT\": DenseSIFT,\n",
    "    \"KAZE\": KAZE,\n",
    "    \"AKAZE\": AKAZE,\n",
    "    \"ORB\": ORB,\n",
    "    \"BRISK\": BRISK\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filenames, labels, descriptor_extractor, extract_features=True):\n",
    "    descriptors = []\n",
    "    label_per_descriptor = []\n",
    "    images = []\n",
    "    \n",
    "    for filename,labels in zip(filenames, labels):\n",
    "        ima=cv2.imread(filename)\n",
    "        gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if extract_features:\n",
    "            des = descriptor_extractor.extract_features(gray)\n",
    "            descriptors.append(des)\n",
    "        else:\n",
    "            images.append(gray)\n",
    "            \n",
    "        label_per_descriptor.append(labels)\n",
    "\n",
    "    if not extract_features:\n",
    "        return images, label_per_descriptor\n",
    "    else:\n",
    "        return descriptors, label_per_descriptor\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. bag of visual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_local_features(features, n_clusters):\n",
    "    codebook = MiniBatchKMeans(n_clusters=n_clusters, verbose=False, batch_size=n_clusters *\n",
    "                               20, compute_labels=False, reassignment_ratio=10**-4, random_state=42)\n",
    "    codebook.fit(features)\n",
    "    return codebook\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCRIPTOR = feature_extractors[\"SIFT\"]()\n",
    "train_descriptors, train_labels_descrip = extract_features(\n",
    "    train_images_filenames, train_labels, DESCRIPTOR)\n",
    "test_descriptors, test_labels_descrip = extract_features(\n",
    "    test_images_filenames, test_labels, DESCRIPTOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = np.vstack(train_descriptors)\n",
    "codebook = cluster_local_features(stack, n_clusters=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_histogram(assigned_clusters, num_clusters):\n",
    "    bag_visual_words = np.zeros(\n",
    "        (len(assigned_clusters), num_clusters), dtype=np.float32)\n",
    "    for i in range(len(assigned_clusters)):\n",
    "        hist_i, _ = np.histogram(\n",
    "            assigned_clusters[i], bins=num_clusters, range=(0, num_clusters))\n",
    "        bag_visual_words[i, :] = normalize(hist_i.reshape(1, -1), norm='l2')\n",
    "    return bag_visual_words\n",
    "\n",
    "\n",
    "def obtain_histogram_visual_words(features, tr_lengths=None, codebook=None):\n",
    "    if tr_lengths is None:\n",
    "        tr_lengths = [len(feature) for feature in features]\n",
    "        features = np.vstack(features)\n",
    "    assigned_labels = codebook.predict(features)\n",
    "    lengths = np.array(\n",
    "        [0]+[descriptor_length for descriptor_length in tr_lengths])\n",
    "    lengths = np.cumsum(lengths)\n",
    "    splitted_labels = [assigned_labels[lengths[i]:lengths[i+1]]\n",
    "                       for i in range(len(lengths)-1)]\n",
    "    return compute_histogram(splitted_labels, codebook.cluster_centers_.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words_train = obtain_histogram_visual_words(\n",
    "    train_descriptors, codebook=codebook)\n",
    "visual_words_test = obtain_histogram_visual_words(\n",
    "    test_descriptors, codebook=codebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1, metric='euclidean')\n",
    "knn.fit(visual_words_train, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation functions\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "cv_strategies = {\n",
    "    \"kfold\": KFold,\n",
    "    \"stratified\": StratifiedKFold,\n",
    "    \"repeats\": RepeatedStratifiedKFold\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"balanced_accuracy\": balanced_accuracy_score,\n",
    "    \"accuracy\": accuracy_score,\n",
    "    \"f1-score\": f1_score,\n",
    "    \"confusion-matrix\": confusion_matrix\n",
    "}\n",
    "\n",
    "\n",
    "class BoVWClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" Image classifier using Bag of Visual Words. \"\"\"\n",
    "\n",
    "    def __init__(self, clustering_method, classifier, reduction_method):\n",
    "        self.clustering_method = clustering_method\n",
    "        self.classifier = classifier\n",
    "        self.reduction_method = reduction_method\n",
    "        self.codebook = None\n",
    "\n",
    "    def fit(self, features, labels, sample_weight=None):\n",
    "        tr_lengths = [len(feature) for feature in features]\n",
    "        features = np.vstack(features)\n",
    "        self.codebook = self.clustering_method(features)\n",
    "        tr_hist = obtain_histogram_visual_words(\n",
    "            features, tr_lengths, self.codebook)\n",
    "        tr_hist_reduced = self.reduction_method.fit_transform(tr_hist, labels)\n",
    "        self.classifier.fit(tr_hist_reduced, labels)\n",
    "\n",
    "    def fit_transform(self, features, labels):\n",
    "        self.fit(features, labels)\n",
    "        return self.predict(features)\n",
    "\n",
    "    def predict_proba(self, features):\n",
    "        te_lengths = [len(feature) for feature in features]\n",
    "        features = np.vstack(features)\n",
    "\n",
    "        te_hist = obtain_histogram_visual_words(\n",
    "            features, te_lengths, self.codebook)\n",
    "        te_hist_reduced = self.reduction_method.transform(te_hist)\n",
    "        cls = self.classifier.predict_proba(te_hist_reduced)\n",
    "        return cls\n",
    "\n",
    "    def predict(self, features):\n",
    "        te_lengths = [len(feature) for feature in features]\n",
    "        features = np.vstack(features)\n",
    "\n",
    "        te_hist = obtain_histogram_visual_words(\n",
    "            features, te_lengths, self.codebook)\n",
    "        te_hist_reduced = self.reduction_method.transform(te_hist)\n",
    "        cls = self.classifier.predict(te_hist_reduced)\n",
    "        return cls\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        return (sum(self.predict(X)))\n",
    "\n",
    "    def score_accuracy(self, X, y):\n",
    "        return 100*self.score(X, y)/len(y)\n",
    "\n",
    "\n",
    "class FastCrossValidator:\n",
    "    \"\"\" Cross-validator class \"\"\"\n",
    "\n",
    "    def __init__(self, cv_method, metric_name, trainer, labels):\n",
    "        \"\"\" \n",
    "        Params:\n",
    "        - cv_method (function): Clustering function that when called returns a codebook.\n",
    "        - classifier (Classifier like KNN, LogisticRegression,...)\n",
    "        - reduction_method (None/PCA/LDA/Isomap)\n",
    "        \"\"\"\n",
    "        self.cv_method = cv_method\n",
    "        self.metric_name = metric_name\n",
    "        self.trainer = trainer\n",
    "        self.labels = np.array(labels)\n",
    "\n",
    "    def cross_validate(self, feature_list, labels, n_jobs=-1):\n",
    "        return cross_val_score(self.trainer, feature_list, labels, scoring=self.metric_name, cv=self.cv_method, n_jobs=n_jobs)\n",
    "\n",
    "\n",
    "class Dummy():\n",
    "    \"\"\" Dummy dimensionality reduction method that keeps all the original features. \"\"\"\n",
    "\n",
    "    def fit_transform(self, features, labels):\n",
    "        return features\n",
    "\n",
    "    def transform(self, features):\n",
    "        return features\n",
    "\n",
    "\n",
    "classifiers = {\"KNN\": KNeighborsClassifier}\n",
    "\n",
    "dim_reduction = {\n",
    "    \"None\": Dummy,\n",
    "    \"PCA\": PCA,\n",
    "    \"LDA\": LinearDiscriminantAnalysis,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words_test = obtain_histogram_visual_words(\n",
    "    test_descriptors, codebook=codebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 100*knn.score(visual_words_test, test_labels)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Dimensonality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "VWpca = pca.fit_transform(visual_words_train)\n",
    "knnpca = KNeighborsClassifier(n_neighbors=5, n_jobs=-1, metric='euclidean')\n",
    "knnpca.fit(VWpca, train_labels)\n",
    "vwtestpca = pca.transform(visual_words_test)\n",
    "accuracy = 100*knnpca.score(vwtestpca, test_labels)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=7)\n",
    "VWlda = lda.fit_transform(visual_words_train, train_labels)\n",
    "knnlda = KNeighborsClassifier(n_neighbors=5, n_jobs=-1, metric='euclidean')\n",
    "knnlda.fit(VWlda, train_labels)\n",
    "vwtestlda = lda.transform(visual_words_test)\n",
    "accuracy = 100*knnlda.score(vwtestlda, test_labels)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.1 \n",
    "● Test different amounts of local features. What performs best?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_local_features(trial):\n",
    "    search_metric = \"balanced_accuracy\"\n",
    "    cv_strategy = cv_strategies[\"stratified\"](n_splits=10)\n",
    "    n_features = int(trial.suggest_int('n_features', 50, 1000))\n",
    "    DESCRIPTOR = feature_extractors[\"SIFT\"](n_features=n_features)\n",
    "    train_descriptors, train_labels_descrip = extract_features(\n",
    "        train_images_filenames, train_labels, DESCRIPTOR)\n",
    "    test_descriptors, test_labels_descrip = extract_features(\n",
    "        test_images_filenames, test_labels, DESCRIPTOR)\n",
    "\n",
    "    clustering = partial(cluster_local_features, n_clusters=128)\n",
    "    dim_reduction_type = dim_reduction[\"None\"]()\n",
    "    classifier = classifiers[\"KNN\"](\n",
    "        n_neighbors=5, n_jobs=8, metric='euclidean')\n",
    "\n",
    "    ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "    ex_cv = FastCrossValidator(\n",
    "        cv_strategy, search_metric, ex_trainer, np.unique(train_labels_descrip))\n",
    "    ex_metrics = ex_cv.cross_validate(\n",
    "        train_descriptors, train_labels_descrip, n_jobs=8)\n",
    "\n",
    "    return ex_metrics.mean()\n",
    "\n",
    "\n",
    "# random, grid search all of you want sampler https://optuna.readthedocs.io/en/stable/reference/samplers/index.html\n",
    "sampler = TPESampler(seed=42)\n",
    "gc.collect()\n",
    "try:\n",
    "    study = optuna.load_study(study_name=\"SIFT\", storage=\"sqlite:///bbdd.db\")\n",
    "except:\n",
    "    study = optuna.create_study(\n",
    "        study_name=\"SIFT\", direction='maximize', sampler=sampler, storage=\"sqlite:///bbdd.db\")\n",
    "    study.optimize(compare_local_features, n_trials=100,\n",
    "                n_jobs=8, gc_after_trial=True)\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"sift.csv\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.2\n",
    "Use dense SIFT instead of detected keypoints. Conclusions?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_models(trial):\n",
    "    search_metric = \"balanced_accuracy\"\n",
    "    cv_strategy = cv_strategies[\"stratified\"](n_splits=10)\n",
    "    n_features = int(trial.suggest_int('n_features', 100, 300))\n",
    "    step_size = int(trial.suggest_int('step_size', 2, 75))\n",
    "    patch_size = int(trial.suggest_int('patch_size', 1, 3))\n",
    "    DESCRIPTOR = feature_extractors[\"DenseSIFT\"](n_features=n_features,\n",
    "        step_size=step_size, patch_size=patch_size)\n",
    "\n",
    "    train_descriptors, train_labels_descrip = extract_features(\n",
    "        train_images_filenames, train_labels, DESCRIPTOR)\n",
    "    test_descriptors, test_labels_descrip = extract_features(\n",
    "        test_images_filenames, test_labels, DESCRIPTOR)\n",
    "\n",
    "    clustering = partial(cluster_local_features, n_clusters=128)\n",
    "    dim_reduction_type = dim_reduction[\"None\"]()\n",
    "    classifier = classifiers[\"KNN\"](\n",
    "        n_neighbors=5, n_jobs=8, metric='euclidean')\n",
    "\n",
    "    ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "    ex_cv = FastCrossValidator(\n",
    "        cv_strategy, search_metric, ex_trainer, np.unique(train_labels_descrip))\n",
    "    ex_metrics = ex_cv.cross_validate(\n",
    "        train_descriptors, train_labels_descrip, n_jobs=8)\n",
    "\n",
    "    return ex_metrics.mean()\n",
    "\n",
    "\n",
    "# random, grid search all of you want sampler https://optuna.readthedocs.io/en/stable/reference/samplers/index.html\n",
    "sampler = TPESampler(seed=42)\n",
    "try:\n",
    "    study = optuna.load_study(study_name=\"DenseSIFT\", storage=\"sqlite:///bbdd.db\")\n",
    "except:\n",
    "    study = optuna.create_study(study_name=\"DenseSIFT\",\n",
    "                                direction='maximize', sampler=sampler, storage=\"sqlite:///bbdd.db\")\n",
    "    study.optimize(compare_models, n_trials=100, n_jobs=8, gc_after_trial=True)\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"densesift.csv\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.3\n",
    "● Test different amounts of codebook sizes k. What performs best?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO\n",
    "def compare_n_clusters(trial):\n",
    "    search_metric = \"balanced_accuracy\"\n",
    "    cv_strategy = cv_strategies[\"stratified\"](n_splits=10)\n",
    "\n",
    "    DESCRIPTOR = feature_extractors[\"DenseSIFT\"](n_features=214,\n",
    "        step_size=15, patch_size=2)\n",
    "\n",
    "    n_clusters = int(trial.suggest_categorical(\n",
    "        'n_clusters', [64, 128, 256, 512, 1024]))\n",
    "\n",
    "    train_descriptors, train_labels_descrip = extract_features(\n",
    "        train_images_filenames, train_labels, DESCRIPTOR)\n",
    "    test_descriptors, test_labels_descrip = extract_features(\n",
    "        test_images_filenames, test_labels, DESCRIPTOR)\n",
    "\n",
    "    clustering = partial(cluster_local_features, n_clusters=n_clusters)\n",
    "    dim_reduction_type = dim_reduction[\"None\"]()\n",
    "    classifier = classifiers[\"KNN\"](\n",
    "        n_neighbors=5, n_jobs=8, metric='euclidean')\n",
    "\n",
    "    ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "    ex_cv = FastCrossValidator(\n",
    "        cv_strategy, search_metric, ex_trainer, np.unique(train_labels_descrip))\n",
    "    ex_metrics = ex_cv.cross_validate(\n",
    "        train_descriptors, train_labels_descrip, n_jobs=8)\n",
    "\n",
    "    return ex_metrics.mean()\n",
    "\n",
    "\n",
    "# random, grid search all of you want sampler https://optuna.readthedocs.io/en/stable/reference/samplers/index.html\n",
    "sampler = TPESampler(seed=42)\n",
    "try:\n",
    "    study = optuna.load_study(study_name=\"compare_n_clusters\", storage=\"sqlite:///bbdd.db\")\n",
    "except:\n",
    "    study = optuna.create_study(study_name=\"compare_n_clusters\",\n",
    "                                direction='maximize', sampler=sampler, storage=\"sqlite:///bbdd.db\")\n",
    "    study.optimize(compare_n_clusters, n_trials=10, n_jobs=8, gc_after_trial=True)\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"n_clusters.csv\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.4\n",
    "● Test different values of k for the k-nn classifier. What performs best?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO\n",
    "def compare_k_classifier(trial):\n",
    "    search_metric = \"balanced_accuracy\"\n",
    "    cv_strategy = cv_strategies[\"stratified\"](n_splits=10)\n",
    "\n",
    "    DESCRIPTOR = feature_extractors[\"DenseSIFT\"](n_features=214,\n",
    "        step_size=15, patch_size=2)\n",
    "\n",
    "    n_neighbors = int(trial.suggest_int('n_neighbors', 1, 10))\n",
    "\n",
    "    train_descriptors, train_labels_descrip = extract_features(\n",
    "        train_images_filenames, train_labels, DESCRIPTOR)\n",
    "    test_descriptors, test_labels_descrip = extract_features(\n",
    "        test_images_filenames, test_labels, DESCRIPTOR)\n",
    "\n",
    "    clustering = partial(cluster_local_features, n_clusters=1024)\n",
    "    dim_reduction_type = dim_reduction[\"None\"]()\n",
    "    classifier = classifiers[\"KNN\"](\n",
    "        n_neighbors=n_neighbors, n_jobs=8, metric='euclidean')\n",
    "\n",
    "    ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "    ex_cv = FastCrossValidator(\n",
    "        cv_strategy, search_metric, ex_trainer, np.unique(train_labels_descrip))\n",
    "    ex_metrics = ex_cv.cross_validate(\n",
    "        train_descriptors, train_labels_descrip, n_jobs=8)\n",
    "\n",
    "    return ex_metrics.mean()\n",
    "\n",
    "\n",
    "# random, grid search all of you want sampler https://optuna.readthedocs.io/en/stable/reference/samplers/index.html\n",
    "sampler = TPESampler(seed=42)\n",
    "try:\n",
    "    study = optuna.load_study(study_name=\"K_classifier\", storage=\"sqlite:///bbdd.db\")\n",
    "except:\n",
    "    study = optuna.create_study(\n",
    "        study_name=\"K_classifier\", direction='maximize', sampler=sampler, storage=\"sqlite:///bbdd.db\")\n",
    "    study.optimize(compare_k_classifier, n_trials=100,\n",
    "                n_jobs=8, gc_after_trial=True)\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"K_classifier.csv\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.5\n",
    "● Test other distances in k-nn classifier. Does that make a difference? Why?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO\n",
    "def compare_distances_classifier(trial):\n",
    "    search_metric = \"balanced_accuracy\"\n",
    "    cv_strategy = cv_strategies[\"stratified\"](n_splits=10)\n",
    "\n",
    "    metric = trial.suggest_categorical(\n",
    "        'metric', [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"])\n",
    "\n",
    "    DESCRIPTOR = feature_extractors[\"DenseSIFT\"](n_features=214,\n",
    "        step_size=15, patch_size=2)\n",
    "\n",
    "    train_descriptors, train_labels_descrip = extract_features(\n",
    "        train_images_filenames, train_labels, DESCRIPTOR)\n",
    "    test_descriptors, test_labels_descrip = extract_features(\n",
    "        test_images_filenames, test_labels, DESCRIPTOR)\n",
    "\n",
    "    clustering = partial(cluster_local_features, n_clusters=256)\n",
    "    dim_reduction_type = dim_reduction[\"None\"]()\n",
    "    classifier = classifiers[\"KNN\"](\n",
    "        n_neighbors=4, n_jobs=8, metric=metric)\n",
    "\n",
    "    ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "    ex_cv = FastCrossValidator(\n",
    "        cv_strategy, search_metric, ex_trainer, np.unique(train_labels_descrip))\n",
    "    ex_metrics = ex_cv.cross_validate(\n",
    "        train_descriptors, train_labels_descrip, n_jobs=8)\n",
    "\n",
    "    return ex_metrics.mean()\n",
    "\n",
    "\n",
    "# random, grid search all of you want sampler https://optuna.readthedocs.io/en/stable/reference/samplers/index.html\n",
    "sampler = TPESampler(seed=42)\n",
    "\n",
    "try:\n",
    "    study = optuna.load_study(study_name=\"Distances\", storage=\"sqlite:///bbdd.db\")\n",
    "except:\n",
    "    study = optuna.create_study(study_name=\"Distances\",\n",
    "                                direction='maximize', sampler=sampler, storage=\"sqlite:///bbdd.db\", load_if_exists=True)\n",
    "    study.optimize(compare_distances_classifier, n_trials=25,\n",
    "                n_jobs=8, gc_after_trial=True)\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"distances.csv\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.6\n",
    "● Play with reducing dimensionality. Conclusions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO\n",
    "def compare_dimensionality(trial):\n",
    "    search_metric = \"balanced_accuracy\"\n",
    "    cv_strategy = cv_strategies[\"stratified\"](n_splits=10)\n",
    "    DESCRIPTOR = feature_extractors[\"DenseSIFT\"](n_features=214,\n",
    "        step_size=15, patch_size=2)\n",
    "\n",
    "    train_descriptors, train_labels_descrip = extract_features(\n",
    "        train_images_filenames, train_labels, DESCRIPTOR)\n",
    "    test_descriptors, test_labels_descrip = extract_features(\n",
    "        test_images_filenames, test_labels, DESCRIPTOR)\n",
    "\n",
    "    dimensionality_reduction = trial.suggest_categorical(\n",
    "        'dimensionality_reduction', [\"PCA\", \"LDA\"])\n",
    "\n",
    "    clustering = partial(cluster_local_features, n_clusters=1024)\n",
    "    dim_reduction_type = dim_reduction[dimensionality_reduction]()\n",
    "    classifier = classifiers[\"KNN\"](\n",
    "        n_neighbors=10, n_jobs=8, metric='euclidean')\n",
    "\n",
    "    ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "    ex_cv = FastCrossValidator(\n",
    "        cv_strategy, search_metric, ex_trainer, np.unique(train_labels_descrip))\n",
    "    ex_metrics = ex_cv.cross_validate(\n",
    "        train_descriptors, train_labels_descrip, n_jobs=8)\n",
    "\n",
    "    return ex_metrics.mean()\n",
    "\n",
    "\n",
    "# random, grid search all of you want sampler https://optuna.readthedocs.io/en/stable/reference/samplers/index.html\n",
    "sampler = TPESampler(seed=42)\n",
    "try:\n",
    "    study = optuna.load_study(study_name=\"Dimensionality_Reduction\", storage=\"sqlite:///bbdd.db\")\n",
    "except:\n",
    "    study = optuna.create_study(\n",
    "        study_name=\"Dimensionality_Reduction\", direction='maximize', sampler=sampler, storage=\"sqlite:///bbdd.db\")\n",
    "    study.optimize(compare_dimensionality, n_trials=100,\n",
    "                n_jobs=8, gc_after_trial=True)\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"compare_dimensionality.csv\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_experiments(trial):\n",
    "    try:\n",
    "        search_metric = \"balanced_accuracy\"\n",
    "        cv_strategy = cv_strategies[\"stratified\"](n_splits=10)\n",
    "        n_features = int(trial.suggest_int('n_features', 100, 300))\n",
    "        step_size = int(trial.suggest_int('step_size', 2, 75))\n",
    "        patch_size = int(trial.suggest_int('patch_size', 1, 3))\n",
    "        _clusters = int(trial.suggest_categorical(\n",
    "            'n_clusters', [64, 128, 256, 512, 1024]))\n",
    "        n_neighbors = int(trial.suggest_int('n_neighbors', 1, 10))\n",
    "        metric = trial.suggest_categorical(\n",
    "            'metric', [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"])\n",
    "        n_components_PCA = int(trial.suggest_int('n_components', 1, 75))\n",
    "        n_components_LDA = int(trial.suggest_int('n_components', 1, 7))\n",
    "\n",
    "        DESCRIPTOR = feature_extractors[\"DenseSIFT\"](n_features=n_features,\n",
    "            step_size=step_size, patch_size=patch_size)\n",
    "        \n",
    "        train_descriptors, train_labels_descrip = extract_features(\n",
    "            train_images_filenames, train_labels, DESCRIPTOR)\n",
    "        test_descriptors, test_labels_descrip = extract_features(\n",
    "            test_images_filenames, test_labels, DESCRIPTOR)\n",
    "\n",
    "        dimensionality_reduction = trial.suggest_categorical(\n",
    "            'dimensionality_reduction', [\"PCA\", \"LDA\"])\n",
    "\n",
    "        clustering = partial(cluster_local_features, n_clusters=_clusters)\n",
    "        if dimensionality_reduction == \"PCA\":\n",
    "            dim_reduction_type = dim_reduction[dimensionality_reduction](n_components=n_components_PCA)\n",
    "        else:\n",
    "            dim_reduction_type = dim_reduction[dimensionality_reduction](n_components=n_components_LDA)\n",
    "        classifier = classifiers[\"KNN\"](\n",
    "            n_neighbors=n_neighbors, n_jobs=8, metric=metric)\n",
    "\n",
    "        ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "        ex_cv = FastCrossValidator(\n",
    "            cv_strategy, search_metric, ex_trainer, np.unique(train_labels_descrip))\n",
    "        ex_metrics = ex_cv.cross_validate(\n",
    "            train_descriptors, train_labels_descrip, n_jobs=8)\n",
    "\n",
    "        return ex_metrics.mean()\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# random, grid search all of you want sampler https://optuna.readthedocs.io/en/stable/reference/samplers/index.html\n",
    "sampler = TPESampler(seed=42)\n",
    "try:\n",
    "    study = optuna.load_study(study_name=\"full_experiments\", storage=\"sqlite:///bbdd.db\")\n",
    "except:\n",
    "    study = optuna.create_study(\n",
    "        study_name=\"full_experiments\", direction='maximize', sampler=sampler, storage=\"sqlite:///bbdd.db\", load_if_exists=True)\n",
    "    study.optimize(full_experiments, n_trials=100,\n",
    "                n_jobs=8, gc_after_trial=True)\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"compare_dimensionality.csv\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE TEST DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will evaluate the best model with the test dataset. \n",
    "\n",
    "The best parameters found for the classifier in our grid search were:\n",
    "- DenseSIFT descriptor using a n_features = 214, patch_size = 2, step size = 15\n",
    "- Clustering: number of clusters k = 1024\n",
    "- Dimensionality reduction = PCA\n",
    "- Classifier: n_neighbors = 10, metric = 'euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best descriptor\n",
    "DESCRIPTOR = feature_extractors[\"DenseSIFT\"](n_features=214, patch_size=2, step_size=15)\n",
    "train_descriptors, train_labels_descrip = extract_features(train_images_filenames, train_labels, DESCRIPTOR)\n",
    "test_descriptors, test_labels_descrip = extract_features(test_images_filenames, test_labels, DESCRIPTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "clustering = partial(cluster_local_features, n_clusters=1024)\n",
    "dim_reduction_type = dim_reduction[\"PCA\"]()\n",
    "classifier = classifiers[\"KNN\"](n_neighbors=10, n_jobs=8, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and compute the time\n",
    "start = time.time()\n",
    "ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "ex_trainer.fit(train_descriptors, train_labels_descrip)\n",
    "end = time.time()\n",
    "print(\"Training time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model and compute the time\n",
    "start = time.time()\n",
    "predictions = ex_trainer.predict(test_descriptors)\n",
    "end = time.time()\n",
    "print(\"Testing time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the f1-score and accuracy for each class\n",
    "def compute_metrics(truth, preds):\n",
    "    results = []\n",
    "    unique_labels = np.unique(truth)\n",
    "    truth, preds = np.array(truth), np.array(preds)\n",
    "    for lab in unique_labels:\n",
    "        acc = metrics[\"accuracy\"](truth == lab, preds == lab)\n",
    "        F1 = metrics[\"f1-score\"](truth == lab, preds == lab)\n",
    "        results.append((lab, acc, F1))\n",
    "\n",
    "    overall_acc = metrics[\"balanced_accuracy\"](truth, preds)\n",
    "    weighted_F1 = metrics[\"f1-score\"](truth, preds, average=\"weighted\")\n",
    "    results.append((\"OVERALL\", overall_acc, weighted_F1))\n",
    "    return pd.DataFrame(data=results, columns=[\"label\", \"accuracy\", \"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the f1-score, accuracy and confusion matrix\n",
    "compute_metrics(test_labels_descrip, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Plot confusion matrix∫\n",
    "labels = [\"Opencountry\", \"coast\", \"forest\", \"mountain\", \"highway\", \"tallbuilding\", \"street\", \"inside_city\"]\n",
    "confusion = confusion_matrix(test_labels_descrip, predictions, labels=labels)\n",
    "    \n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "g = sns.heatmap(confusion,cbar=True,annot=True, cmap=\"Blues\")#, xticklabels=labels, yticklabels=labels,)\n",
    "g.set_title('Confusion matrix')\n",
    "\n",
    "g.set_ylabel('Truth')\n",
    "g.set_xlabel('Predicted')\n",
    "g.set_yticklabels(labels, rotation=0)\n",
    "g.set_xticklabels(labels, rotation=60)\n",
    "g.xaxis.tick_top()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "precision =(confusion/confusion.sum(axis=0))\n",
    "recall =(((confusion.T)/(confusion.sum(axis=1))).T)\n",
    "f_score = np.nan_to_num((2 * (precision * recall) / (precision + recall)))\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "g = sns.heatmap(f_score,cmap=\"Blues\", annot=True, fmt=\".2f\", xticklabels=labels, yticklabels=labels)\n",
    "g.set_title('F1-score matrix')\n",
    "\n",
    "g.set_ylabel('Truth')\n",
    "g.set_xlabel('Predicted')\n",
    "g.set_yticklabels(labels, rotation=0)\n",
    "g.set_xticklabels(labels, rotation=60)\n",
    "g.xaxis.tick_top()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FP(truth, preds, cls):\n",
    "    return np.where((np.array(truth) != cls) & (preds == cls))\n",
    "\n",
    "def get_FN(truth, preds, cls):\n",
    "    return np.where((np.array(truth) == cls) & (preds != cls))\n",
    "\n",
    "def get_TP(truth, preds, cls):\n",
    "    return np.where((np.array(truth) == cls) & (preds == cls))\n",
    "\n",
    "def plot_idxs(truth, preds, idxs):\n",
    "    total = len(idxs[0])\n",
    "    COLS = 5\n",
    "    rows, cols = max(2, total // COLS + 1), COLS\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(30,3*rows))\n",
    "    \n",
    "    for i in range(rows * cols):\n",
    "        r, c = i // cols, i % cols\n",
    "        if i >= total:\n",
    "            fig.delaxes(axs[r,c])\n",
    "            continue\n",
    "        img = cv2.imread(test_images_filenames[idxs[0][i]])\n",
    "        axs[r,c].set_title(f\"{idxs[0][i]}\\n{truth[idxs[0][i]]}\")\n",
    "        axs[r,c].axis(\"off\")\n",
    "        axs[r,c].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab in labels:\n",
    "    print(f\"> Wrongly predicted as {lab}\\n\")\n",
    "    plot_idxs(test_labels_descrip, predictions, get_FP(test_labels_descrip, predictions, lab))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
