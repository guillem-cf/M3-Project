{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 1\n",
    "- Guillem\n",
    "- Anna\n",
    "- Johnny"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "● Test different amounts of local features. What performs best?  \n",
    "● Use dense SIFT instead of detected keypoints. Conclusions?  \n",
    "● Test different amounts of codebook sizes k. What performs best?  \n",
    "● Test different values of k for the k-nn classifier. What performs best?  \n",
    "● Test other distances in k-nn classifier. Does that make a difference? Why?  \n",
    "● Play with reducing dimensionality. Conclusions?  \n",
    "● Cross-validate everything (topic covered on Wednesday)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import optuna\n",
    "from optuna.visualization.matplotlib import plot_contour, plot_edf, plot_intermediate_values, plot_optimization_history, plot_parallel_coordinate, plot_param_importances, plot_slice\n",
    "import os\n",
    "from optuna.samplers import TPESampler\n",
    "import concurrent.futures\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read the train and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filenames = pickle.load(\n",
    "    open('MIT_split/train_images_filenames_unix.dat', 'rb'))\n",
    "test_images_filenames = pickle.load(\n",
    "    open('MIT_split/test_images_filenames_unix.dat', 'rb'))\n",
    "# train_images_filenames = ['..' + n[15:] for n in train_images_filenames] original\n",
    "# test_images_filenames  = ['..' + n[15:] for n in test_images_filenames]  original\n",
    "train_images_filenames = [n[16:] for n in train_images_filenames]\n",
    "test_images_filenames = [n[16:] for n in test_images_filenames]\n",
    "train_labels = pickle.load(open('MIT_split/train_labels_unix.dat', 'rb'))\n",
    "test_labels = pickle.load(open('MIT_split/test_labels_unix.dat', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MIT_split/train/Opencountry/fie26.jpg'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_filenames[12]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Distribution Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set class proportions: [0.15523658 0.12971823 0.12068049 0.09782031 0.11376927 0.13822435\n",
      " 0.11270601 0.13184476]\n",
      "Test set class proportions: [0.14622057 0.14374226 0.12515489 0.09417596 0.11648079 0.14126394\n",
      " 0.09913259 0.133829  ]\n"
     ]
    }
   ],
   "source": [
    "unique_classes, counts = np.unique(train_labels, return_counts=True)\n",
    "total_count = sum(counts)\n",
    "train_class_proportions = counts / total_count\n",
    "\n",
    "# Calculate the class proportions for the test set\n",
    "unique_classes, counts = np.unique(test_labels, return_counts=True)\n",
    "total_count = sum(counts)\n",
    "test_class_proportions = counts / total_count\n",
    "\n",
    "# Print the class proportions for the train and test sets\n",
    "print(\"Train set class proportions:\", train_class_proportions)\n",
    "print(\"Test set class proportions:\", test_class_proportions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAHBCAYAAAC/l6ndAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABY2ElEQVR4nO3dd3gU1eL/8c+SsqmEFMgmEhJ6uTQBpakJXRBQ8QqIcokCFjAYEbGgECxwRWmC4hURlCKoiAWQLogiUgSp0gyCmIggvQRIzu8Pfpkvmx4IDMj79TzzPOzMmTlnZmeXT87MmXUYY4wAAAAAmxSzuwEAAAC4vhFIAQAAYCsCKQAAAGxFIAUAAICtCKQAAACwFYEUAAAAtiKQAgAAwFYEUgAAANiKQAoAAABbEUgBSZMmTZLD4bAmHx8fuVwuNWnSREOHDtX+/fuzrZOUlCSHw1Goek6ePKmkpCQtXbq0UOvlVFdMTIzatm1bqO3kZ9q0aRo1alSOyxwOh5KSkoq0vqK2ePFi1atXT/7+/nI4HPr8889zLPfHH38oKSlJ69evz7YsPj5eAQEBl7ehkubOnXtZj2dcXJzi4uIuat2LObevRTExMYqPj8+zzMV+ZgtrxYoVSkpK0uHDhy9rPTm53OciUBAEUuACEydO1A8//KCFCxfqrbfeUu3atfXaa6+patWqWrRokVvZHj166IcffijU9k+ePKnBgwcX+j+3i6nrYuQVSH/44Qf16NHjsrfhYhlj1LFjR3l5eenLL7/UDz/8oNjY2BzL/vHHHxo8eHCOgfRKmTt3rgYPHnzZtv/222/r7bffvqh1r9T5di242M9sYa1YsUKDBw+2LZBeznMRKAhPuxsAXE2qV6+uevXqWa/vuecePfnkk7rlllvUoUMH7dixQ+Hh4ZKk0qVLq3Tp0pe1PSdPnpSfn98VqSs/DRo0sLX+/Pzxxx/6+++/dffdd6tZs2Z2N6dIGWN0+vRp+fr6FnidatWqXXR9V8P5BuA6YwCYiRMnGklm9erVOS7/+OOPjSQzePBga96gQYNM1o/Q4sWLTWxsrAkJCTE+Pj4mKirKdOjQwZw4ccIkJycbSdmmbt26uW1v7dq15p577jElSpQwLpcr17qio6PNHXfcYT777DNTo0YN43Q6TdmyZc3o0aNz3Lfk5GS3+d98842RZL755htjjDGxsbE5ti+TJDNo0CC3bWzcuNG0b9/elChRwjidTlOrVi0zadKkHOuZNm2aef75501ERIQJDAw0zZo1M7/88kuOxzur5cuXm6ZNm5qAgADj6+trGjZsaGbPnp3tvbhwio6OznFbme3JOmXuW7du3Yy/v7/ZsWOHad26tfH39zelS5c2ffv2NadPn3bbVlpamnn55ZdN5cqVjbe3twkLCzPx8fFm//79ee5Pt27dcmxD5nskyfTu3duMGzfOVKlSxXh5eZlx48YZY4xJSkoyN998swkODjaBgYHmxhtvNO+9957JyMhwqyM2NtbExsZarzPPv9dff90MHz7cxMTEGH9/f9OgQQPzww8/uK2b1/n29ddfmxtvvNH4+PiYypUrmwkTJmTbv+XLl5sGDRoYp9NpIiMjzQsvvGDGjx+f43mY1erVq02nTp1MdHS08fHxMdHR0aZz585m9+7dbuUyz+slS5aYRx991ISGhpqQkBBz9913m3379rmVPXPmjHn66adNeHi48fX1NY0bNzY//vijiY6Otj5/OcnvM2uMMdu3bzf33XefKVmypPH29jZVqlQxY8eOddtOenq6efnll02lSpWMj4+PCQoKMjVq1DCjRo1yO95Zp8zPZk527dplOnXqZCIiIoy3t7cpVaqUadq0qVm3bp1buenTp5sGDRoYPz8/4+/vb1q2bGl++ukna3l+5yJwpdBDChRAmzZt5OHhoW+//TbXMrt379Ydd9yhW2+9Ve+//75KlCihffv2ad68eTpz5owiIiI0b9483X777erevbt1+btkyZJu2+nQoYM6d+6sRx99VCdOnMizXevXr1diYqKSkpLkcrk0depUPfHEEzpz5oz69etXqH18++239fDDD2vXrl2aNWtWvuW3bdumRo0aqVSpUnrzzTcVGhqqKVOmKD4+Xn/++af69+/vVv75559X48aN9d577+no0aN65pln1K5dO23dulUeHh651rNs2TK1aNFCNWvW1IQJE+R0OvX222+rXbt2+uijj9SpUyf16NFDtWrVUocOHZSQkKAuXbrI6XTmuL06depo4sSJevDBB/XCCy/ojjvukCS3HsGzZ8+qffv26t69u5566il9++23evnllxUUFKSBAwdKkjIyMnTnnXdq+fLl6t+/vxo1aqTffvtNgwYNUlxcnNasWZNrj+aLL76oEydO6NNPP3W7NB4REWH9+/PPP9fy5cs1cOBAuVwulSpVStL58+yRRx5RmTJlJEkrV65UQkKC9u3bZ7UtL2+99ZaqVKli3Zrx4osvqk2bNkpOTlZQUFCe6/7888966qmn9Oyzzyo8PFzvvfeeunfvrgoVKui2226TJG3YsEEtWrRQpUqV9MEHH8jPz0/vvPOOpkyZkm/bMvevcuXK6ty5s0JCQpSSkqJx48bppptu0pYtWxQWFuZWvkePHrrjjjs0bdo07d27V08//bQeeOABLVmyxCrTs2dPffjhh+rXr59atGihTZs2qUOHDjp27FiebcnvM7tlyxY1atRIZcqU0fDhw+VyuTR//nz16dNHBw4c0KBBgyRJw4YNU1JSkl544QXddtttOnv2rH755Rfr8nyPHj30999/a8yYMfrss8+s8yCvXu42bdooPT1dw4YNU5kyZXTgwAGtWLHC7ZL/kCFD9MILL1jn+pkzZ/T666/r1ltv1apVq1StWrUCnYvAFWF3IgauBvn1kBpjTHh4uKlatar1Omsv0qeffmokmfXr1+e6jb/++ivHnsYLtzdw4MBcl10oOjraOByObPW1aNHCFC9e3Jw4ccJt3/LrITXGmDvuuCPXnsWs7e7cubNxOp1mz549buVat25t/Pz8zOHDh93qadOmjVu5zF7nrL1zWTVo0MCUKlXKHDt2zJp37tw5U716dVO6dGmrZ/DCHsD8rF692kgyEydOzLYss8fo448/dpvfpk0bU7lyZev1Rx99ZCSZmTNn5rjtt99+O8829O7dO9t7mkmSCQoKMn///Xee20hPTzdnz541L730kgkNDXXrJc2th7RGjRrm3Llz1vxVq1YZSeajjz6y5uV2vvn4+JjffvvNmnfq1CkTEhJiHnnkEWvevffea/z9/c1ff/3l1s5q1apdVM/buXPnzPHjx42/v79b73/med2rVy+38sOGDTOSTEpKijHGmK1btxpJ5sknn3QrN3Xq1Gy9nTnJ6zPbqlUrU7p0aXPkyBG3+Y8//rjx8fGx3r+2bdua2rVr51nP66+/XuDjc+DAASPJ6mHNyZ49e4ynp6dJSEhwm3/s2DHjcrlMx44drXl5nYvAlcKgJqCAjDF5Lq9du7a8vb318MMP64MPPtCvv/56UfXcc889BS77r3/9S7Vq1XKb16VLFx09elQ//fTTRdVfUEuWLFGzZs0UFRXlNj8+Pl4nT57MNiimffv2bq9r1qwpSfrtt99yrePEiRP68ccf9e9//9tt5LuHh4e6du2q33//Xdu2bbvUXcnG4XCoXbt22dp7YVtnz56tEiVKqF27djp37pw11a5dWy6X65IHwTRt2lTBwcHZ5i9ZskTNmzdXUFCQPDw85OXlpYEDB+rgwYM5Pg0iqzvuuMOtR7og70Om2rVrWz2zkuTj46NKlSq5rbts2TI1bdrUrSezWLFi6tixY77bl6Tjx4/rmWeeUYUKFeTp6SlPT08FBAToxIkT2rp1a7by+Z1X33zzjSTp/vvvdyvXsWNHeXpe/EXC06dPa/Hixbr77rvl5+fndg60adNGp0+f1sqVKyVJN998s37++Wf16tVL8+fP19GjRy+6XkkKCQlR+fLl9frrr2vEiBFat26dMjIy3MrMnz9f586d03/+8x+3tvn4+Cg2NvayD9ICCotAChTAiRMndPDgQUVGRuZapnz58lq0aJFKlSql3r17q3z58ipfvrxGjx5dqLoKc6nM5XLlOu/gwYOFqrewDh48mGNbM49R1vpDQ0PdXmdeUj916lSudRw6dEjGmELVUxT8/Pzk4+PjNs/pdOr06dPW6z///FOHDx+Wt7e3vLy83KbU1FQdOHDgktqQ0z6vWrVKLVu2lCSNHz9e33//vVavXq0BAwZIyvtYZrqY9yG3dTPXv3DdgwcPWgP/LpTTvJx06dJFY8eOVY8ePTR//nytWrVKq1evVsmSJXNsY377k3l+ZP2seHp65rg/BXXw4EGdO3dOY8aMyfb+t2nTRpKsc+C5557TG2+8oZUrV6p169YKDQ1Vs2bNtGbNmouq2+FwaPHixWrVqpWGDRumOnXqqGTJkurTp491G8Kff/4pSbrpppuytW/GjBmXfH4CRY17SIECmDNnjtLT0/N9ruOtt96qW2+9Venp6VqzZo3GjBmjxMREhYeHq3PnzgWqqzDPf0xNTc11XuZ/tpnBKi0tza3cpf6HFBoaqpSUlGzz//jjD0nKdq/fxQgODlaxYsUuez0XIywsTKGhoZo3b16OywMDAy9p+zmdB9OnT5eXl5dmz57tFphze96qHUJDQ60wdKGcztWsjhw5otmzZ2vQoEF69tlnrflpaWn6+++/L7o9mfXfcMMN1vxz585d0h8zwcHBVk997969cyxTtmxZSefDb9++fdW3b18dPnxYixYt0vPPP69WrVpp79698vPzK3T90dHRmjBhgiRp+/bt+vjjj5WUlKQzZ87onXfesT4Xn376qaKjoy9yL4Erh0AK5GPPnj3q16+fgoKC9MgjjxRoHQ8PD9WvX19VqlTR1KlT9dNPP6lz586F6o0qiM2bN+vnn392u2w/bdo0BQYGqk6dOpLOP/xbOj/YpHLlyla5L7/8Mtv2svZ25aVZs2aaNWuW/vjjD7ee4w8//FB+fn5F8pgof39/1a9fX5999pneeOMNa5BQRkaGpkyZotKlS6tSpUqF3m5RvA9t27bV9OnTlZ6ervr1619SGwr6OCeHwyFPT0+3S+6nTp3S5MmTC13/5RIbG6u5c+fqwIEDVijKyMjQJ598ku+6DodDxphsA9Lee+89paenX1R7Mv+InDp1qurWrWvN//jjj3Xu3Ll818/tXPHz81OTJk20bt061axZU97e3gVqT4kSJfTvf/9b+/btU2Jionbv3q1q1apd0jlZqVIlvfDCC5o5c6Z1q06rVq3k6empXbt25Xsb0MWci0BRI5ACF9i0aZN1r9X+/fu1fPlyTZw4UR4eHpo1a1a2EfEXeuedd7RkyRLdcccdKlOmjE6fPq33339fktS8eXNJ53vNoqOj9cUXX6hZs2YKCQlRWFiYFRoLKzIyUu3bt1dSUpIiIiI0ZcoULVy4UK+99prV63LTTTepcuXK6tevn86dO6fg4GDNmjVL3333Xbbt1ahRQ5999pnGjRununXrqlixYm7PZb3QoEGDNHv2bDVp0kQDBw5USEiIpk6dqjlz5mjYsGH5jtguqKFDh6pFixZq0qSJ+vXrJ29vb7399tvatGmTPvroo4v6RaHy5cvL19dXU6dOVdWqVRUQEKDIyMg8b8nIqnPnzpo6daratGmjJ554QjfffLO8vLz0+++/65tvvtGdd96pu+++O9f1a9SoIUl67bXX1Lp1a3l4eOQbbO644w6NGDFCXbp00cMPP6yDBw/qjTfeyPWJAnYYMGCAvvrqKzVr1kwDBgyQr6+v3nnnHeuJEcWK5X6nWPHixXXbbbfp9ddftz4Xy5Yt04QJE1SiRImLak/VqlX1wAMPaNSoUfLy8lLz5s21adMmvfHGGypevHi+6+f1mR09erRuueUW3XrrrXrssccUExOjY8eOaefOnfrqq6+skf7t2rWznnFcsmRJ/fbbbxo1apSio6NVsWJFSf93PowePVrdunWTl5eXKleunGNP+4YNG/T444/r3nvvVcWKFeXt7a0lS5Zow4YNVs9yTEyMXnrpJQ0YMEC//vqrbr/9dgUHB+vPP//UqlWr5O/vbz0M/2LORaDI2TyoCrgqZI7YzZwyn+sXGxtrhgwZkuNzJbOORP7hhx/M3XffbaKjo43T6TShoaEmNjbWfPnll27rLVq0yNx4443G6XTm+BzSC0cn51aXMf/3XMhPP/3U/Otf/zLe3t4mJibGjBgxItv627dvNy1btjTFixc3JUuWNAkJCWbOnDnZRtn//fff5t///rcpUaKEcTgcBXoOabt27UxQUJDx9vY2tWrVyjZyPXOU/SeffOI2P3PUd04j3bPKfA6pv7+/8fX1NQ0aNDBfffVVjtsryCh7Y86Pks98xueF+5b5HNKscnoPzp49a9544w1Tq1Yt4+PjYwICAkyVKlXMI488Ynbs2JFn/WlpaaZHjx6mZMmS1rHO+hzSnLz//vumcuXKxul0mnLlypmhQ4eaCRMmZBuhnddzSLPK+t7mdb5llbUeY86/X/Xr1zdOp9O4XC7z9NNPm9dee81Isp6+kJvff//d3HPPPdZzVm+//XazadOmbM8Mze3JGDk9PSItLc089dRTplSpUsbHx8d69mp+zyHNlNtn1pjzx/Whhx4yN9xwg/Hy8jIlS5Y0jRo1Mq+88opVZvjw4aZRo0YmLCzMeHt7mzJlypju3btne7bqc889ZyIjI02xYsXyfA7pn3/+aeLj402VKlWMv7+/CQgIMDVr1jQjR450e4KCMcZ8/vnnpkmTJqZ48eLG6XSa6Oho8+9//9ssWrTI7fjkdi4CV4rDmHyGDgMAcIlatmyp3bt3a/v27XY3BcBViEv2AIAi1bdvX914442KiorS33//ralTp2rhwoXWIBwAyIpACgAoUunp6Ro4cKBSU1PlcDhUrVo1TZ48WQ888IDdTQNwleKSPQAAAGzFg/EBAABgKwIpAAAAbEUgBQAAgK2uyUFNGRkZ+uOPPxQYGHhRD8UGAADA5WWM0bFjxxQZGZnnj2JI12gg/eOPPxQVFWV3MwAAAJCPvXv3qnTp0nmWuSYDaeZPqe3du7dAP/0GAACAK+vo0aOKiorK8Sdws7omA2nmZfrixYsTSAEAAK5iBbm9kkFNAAAAsFWhAum4ceNUs2ZNq2eyYcOG+vrrr63lxhglJSUpMjJSvr6+iouL0+bNm922kZaWpoSEBIWFhcnf31/t27fX77//XjR7AwAAgGtOoQJp6dKl9d///ldr1qzRmjVr1LRpU915551W6Bw2bJhGjBihsWPHavXq1XK5XGrRooWOHTtmbSMxMVGzZs3S9OnT9d133+n48eNq27at0tPTi3bPAAAAcE245J8ODQkJ0euvv66HHnpIkZGRSkxM1DPPPCPpfG9oeHi4XnvtNT3yyCM6cuSISpYsqcmTJ6tTp06S/m/E/Ny5c9WqVasC1Xn06FEFBQXpyJEj3EMKAIBN0tPTdfbsWbubARt5e3vn+kinwuS1ix7UlJ6erk8++UQnTpxQw4YNlZycrNTUVLVs2dIq43Q6FRsbqxUrVuiRRx7R2rVrdfbsWbcykZGRql69ulasWJFrIE1LS1NaWprbDgIAAHsYY5SamqrDhw/b3RTYrFixYipbtqy8vb0vaTuFDqQbN25Uw4YNdfr0aQUEBGjWrFmqVq2aVqxYIUkKDw93Kx8eHq7ffvtNkpSamipvb28FBwdnK5OampprnUOHDtXgwYML21QAAHAZZIbRUqVKyc/Pjx+puU5l/lBRSkqKypQpc0nnQaEDaeXKlbV+/XodPnxYM2fOVLdu3bRs2TJredbGGGPybWB+ZZ577jn17dvXep35XCsAAHBlpaenW2E0NDTU7ubAZiVLltQff/yhc+fOycvL66K3U+jHPnl7e6tChQqqV6+ehg4dqlq1amn06NFyuVySlK2nc//+/Vavqcvl0pkzZ3To0KFcy+TE6XRaI/t59igAAPbJvGfUz8/P5pbgapB5qf5SB6df8nNIjTFKS0tT2bJl5XK5tHDhQmvZmTNntGzZMjVq1EiSVLduXXl5ebmVSUlJ0aZNm6wyAADg6sdlekhFdx4U6pL9888/r9atWysqKkrHjh3T9OnTtXTpUs2bN08Oh0OJiYkaMmSIKlasqIoVK2rIkCHy8/NTly5dJElBQUHq3r27nnrqKYWGhiokJET9+vVTjRo11Lx58yLZIQAAAFxbChVI//zzT3Xt2lUpKSkKCgpSzZo1NW/ePLVo0UKS1L9/f506dUq9evXSoUOHVL9+fS1YsMDtN0xHjhwpT09PdezYUadOnVKzZs00adIkeXh4FO2eAQAAXGZxcXGqXbu2Ro0aVaDyu3fvVtmyZbVu3TrVrl37srbtWnLJzyG1A88hBQDAHqdPn1ZycrLKli0rHx8ft2Uxz865Yu3Y/d87ClU+v0vL3bp106RJkwrdjr///lteXl5unW95SU9P119//aWwsDB5el700zcLZObMmRo2bJh++eUXZWRkqEyZMrr99ts1fPjwAm/D4XBo1qxZuuuuu3Jcntf5cEWeQwoAAHCtSElJsf49Y8YMDRw4UNu2bbPm+fr6upU/e/ZsgUaNh4SEFKodHh4e1kDwy2nRokXq3LmzhgwZovbt28vhcGjLli1avHjxZa/7YlzyoCYAAICrncvlsqagoCA5HA7r9enTp1WiRAl9/PHHiouLk4+Pj6ZMmaKDBw/qvvvuU+nSpeXn56caNWroo48+cttuXFycEhMTrdcxMTEaMmSIHnroIQUGBqpMmTJ69913reW7d++Ww+HQ+vXrJUlLly6Vw+HQ4sWLVa9ePfn5+alRo0ZuYVmSXnnlFZUqVUqBgYHq0aOHnn322Twv+c+ePVu33HKLnn76aVWuXFmVKlXSXXfdpTFjxriV++qrr1S3bl35+PioXLlyGjx4sM6dO2ftiyTdfffdcjgc1uvLgUAKAAAg6ZlnnlGfPn20detWtWrVSqdPn1bdunU1e/Zsbdq0SQ8//LC6du2qH3/8Mc/tDB8+XPXq1dO6devUq1cvPfbYY/rll1/yXGfAgAEaPny41qxZI09PTz300EPWsqlTp+rVV1/Va6+9prVr16pMmTIaN25cnttzuVzavHmzNm3alGuZ+fPn64EHHlCfPn20ZcsW/e9//9OkSZP06quvSpJWr14tSZo4caJSUlKs15cDl+wL4UreG2OXwt6TAwDAP0ViYqI6dOjgNq9fv37WvxMSEjRv3jx98sknql+/fq7badOmjXr16iXpfMgdOXKkli5dqipVquS6zquvvqrY2FhJ0rPPPqs77rhDp0+flo+Pj8aMGaPu3bvrwQcflCQNHDhQCxYs0PHjx3PdXkJCgpYvX64aNWooOjpaDRo0UMuWLXX//ffL6XRadT777LPq1q2bJKlcuXJ6+eWX1b9/fw0aNEglS5aUJJUoUeKy32ZADykAAICkevXqub1OT0/Xq6++qpo1ayo0NFQBAQFasGCB9uzZk+d2atasaf0789aA/fv3F3idiIgISbLW2bZtm26++Wa38llfZ+Xv7685c+Zo586deuGFFxQQEKCnnnpKN998s06ePClJWrt2rV566SUFBARYU8+ePZWSkmKVuVLoIQUAAND5EHeh4cOHa+TIkRo1apRq1Kghf39/JSYm6syZM3luJ+tgKIfDoYyMjAKvk/lEgAvXyemn2QuifPnyKl++vHr06KEBAwaoUqVKmjFjhh588EFlZGRo8ODB2XqFJWUbMX+5EUgBAABysHz5ct1555164IEHJJ0PiDt27FDVqlWvaDsqV66sVatWqWvXrta8NWvWFHo7MTEx8vPz04kTJyRJderU0bZt21ShQoVc1/Hy8rrknwUtCAIpAABADipUqKCZM2dqxYoVCg4O1ogRI5SamnrFA2lCQoJ69uypevXqqVGjRpoxY4Y2bNigcuXK5bpOUlKSTp48qTZt2ig6OlqHDx/Wm2++qbNnz1o/aDRw4EC1bdtWUVFRuvfee1WsWDFt2LBBGzdu1CuvvCLpfIhdvHixGjduLKfTqeDg4Muyj9xDCgAAkIMXX3xRderUUatWrRQXFyeXy5XrA+Ivp/vvv1/PPfec+vXrpzp16ig5OVnx8fF5XlaPjY3Vr7/+qv/85z+qUqWKWrdurdTUVC1YsECVK1eWJLVq1UqzZ8/WwoULddNNN6lBgwYaMWKEoqOjre0MHz5cCxcuVFRUlG688cbLto/8UlMhMMoeAHC9y+uXeXDltGjRQi6XS5MnT7a1HfxSEwAAwHXg5MmTeuedd9SqVSt5eHjoo48+0qJFi7Rw4UK7m1ZkCKQAAABXMYfDoblz5+qVV15RWlqaKleurJkzZ6p58+Z2N63IEEgBAACuYr6+vlq0aJHdzbisGNQEAAAAWxFIAQAAYCsCKQAAAGxFIAUAAICtCKQAAACwFYEUAAAAtiKQAgAAwFY8hxQAABSNpKArWNeRQhV3OBx5Lu/WrZsmTZp0UU2JiYlRYmKiEhMT8yy3bt06vfjii1q1apWOHj0ql8ul+vXr66233lJYWFiB6oqLi1Pt2rU1atSoi2rr1YpACgAA/vFSUlKsf8+YMUMDBw7Utm3brHm+vr6Xtf79+/erefPmateunebPn68SJUooOTlZX375pU6ePHlZ674WcMkeAAD847lcLmsKCgqSw+Fwm/ftt9+qbt268vHxUbly5TR48GCdO3fOWj8pKUllypSR0+lUZGSk+vTpI+l8j+Vvv/2mJ598Ug6HI9ee2BUrVujo0aN67733dOONN6ps2bJq2rSpRo0apTJlyljltmzZojZt2iggIEDh4eHq2rWrDhw4IEmKj4/XsmXLNHr0aKuu3bt3X76DdgURSAEAwHVt/vz5euCBB9SnTx9t2bJF//vf/zRp0iS9+uqrkqRPP/1UI0eO1P/+9z/t2LFDn3/+uWrUqCFJ+uyzz1S6dGm99NJLSklJceuJvZDL5dK5c+c0a9YsGWNyLJOSkqLY2FjVrl1ba9as0bx58/Tnn3+qY8eOkqTRo0erYcOG6tmzp1VXVFTUZTgiVx6X7AEAwHXt1Vdf1bPPPqtu3bpJksqVK6eXX35Z/fv316BBg7Rnzx65XC41b95cXl5eKlOmjG6++WZJUkhIiDw8PBQYGCiXy5VrHQ0aNNDzzz+vLl266NFHH9XNN9+spk2b6j//+Y/Cw8MlSePGjVOdOnU0ZMgQa733339fUVFR2r59uypVqiRvb2/5+fnlWde1iB5SAABwXVu7dq1eeuklBQQEWFNmL+TJkyd177336tSpUypXrpx69uypWbNmuV3OL6hXX31Vqampeuedd1StWjW98847qlKlijZu3Gi145tvvnFrR5UqVSRJu3btKtJ9vtoQSAEAwHUtIyNDgwcP1vr1661p48aN2rFjh3x8fBQVFaVt27bprbfekq+vr3r16qXbbrtNZ8+eLXRdoaGhuvfeezV8+HBt3bpVkZGReuONN6x2tGvXzq0d69ev144dO3TbbbcV9W5fVbhkDwAArmt16tTRtm3bVKFChVzL+Pr6qn379mrfvr169+5t9WzWqVNH3t7eSk9PL3S93t7eKl++vE6cOGG1Y+bMmYqJiZGnZ84R7WLrutoRSAEAwHVt4MCBatu2raKionTvvfeqWLFi2rBhgzZu3KhXXnlFkyZNUnp6uurXry8/Pz9NnjxZvr6+io6OlnT+OaTffvutOnfuLKfTmeMzRWfPnq3p06erc+fOqlSpkowx+uqrrzR37lxNnDhRktS7d2+NHz9e9913n55++mmFhYVp586dmj59usaPHy8PDw/FxMToxx9/1O7duxUQEKCQkBAVK3btX/C+9vcAAADgErRq1UqzZ8/WwoULddNNN6lBgwYaMWKEFThLlCih8ePHq3HjxqpZs6YWL16sr776SqGhoZKkl156Sbt371b58uVVsmTJHOuoVq2a/Pz89NRTT6l27dpq0KCBPv74Y7333nvq2rWrJCkyMlLff/+90tPT1apVK1WvXl1PPPGEgoKCrNDZr18/eXh4qFq1aipZsqT27NlzBY7Q5ecwuT174Cp29OhRBQUF6ciRIypevPgVqzfm2TlXrC677P7vHXY3AQBwFTt9+rSSk5NVtmxZ+fj42N0c2Cyv86EweY0eUgAAANiKQAoAAABbEUgBAABgKwIpAAAAbEUgBQAAhXYNjonGZVBU5wGBFAAAFJiXl5ck6eTJkza3BFeDM2fOSJI8PDwuaTs8GB8AABSYh4eHSpQoof3790uS/Pz85HA4bG4V7JCRkaG//vpLfn5+uf6yVEERSAEAQKG4XC5JskIprl/FihVTmTJlLvmPEgIpAAAoFIfDoYiICJUqVUpnz561uzmwkbe3d5H8dCmBFAAAXBQPD49LvncQkBjUBAAAAJsRSAEAAGArAikAAABsxT2kAIB/hJhn59jdhCti93/vsLsJQJGjhxQAAAC2IpACAADAVgRSAAAA2IpACgAAAFsRSAEAAGArAikAAABsRSAFAACArQoVSIcOHaqbbrpJgYGBKlWqlO666y5t27bNrUx8fLwcDofb1KBBA7cyaWlpSkhIUFhYmPz9/dW+fXv9/vvvl743AAAAuOYUKpAuW7ZMvXv31sqVK7Vw4UKdO3dOLVu21IkTJ9zK3X777UpJSbGmuXPnui1PTEzUrFmzNH36dH333Xc6fvy42rZtq/T09EvfIwAAAFxTCvVLTfPmzXN7PXHiRJUqVUpr167VbbfdZs13Op1yuVw5buPIkSOaMGGCJk+erObNm0uSpkyZoqioKC1atEitWrUq7D4AAADgGnZJ95AeOXJEkhQSEuI2f+nSpSpVqpQqVaqknj17av/+/daytWvX6uzZs2rZsqU1LzIyUtWrV9eKFStyrCctLU1Hjx51mwAAAPDPcNGB1Bijvn376pZbblH16tWt+a1bt9bUqVO1ZMkSDR8+XKtXr1bTpk2VlpYmSUpNTZW3t7eCg4PdthceHq7U1NQc6xo6dKiCgoKsKSoq6mKbDQAAgKtMoS7ZX+jxxx/Xhg0b9N1337nN79Spk/Xv6tWrq169eoqOjtacOXPUoUOHXLdnjJHD4chx2XPPPae+fftar48ePUooBQAA+Ie4qB7ShIQEffnll/rmm29UunTpPMtGREQoOjpaO3bskCS5XC6dOXNGhw4dciu3f/9+hYeH57gNp9Op4sWLu00AAAD4ZyhUD6kxRgkJCZo1a5aWLl2qsmXL5rvOwYMHtXfvXkVEREiS6tatKy8vLy1cuFAdO3aUJKWkpGjTpk0aNmzYRewCAADApYl5do7dTbgidv/3DrubkKNCBdLevXtr2rRp+uKLLxQYGGjd8xkUFCRfX18dP35cSUlJuueeexQREaHdu3fr+eefV1hYmO6++26rbPfu3fXUU08pNDRUISEh6tevn2rUqGGNugcAAMD1o1CBdNy4cZKkuLg4t/kTJ05UfHy8PDw8tHHjRn344Yc6fPiwIiIi1KRJE82YMUOBgYFW+ZEjR8rT01MdO3bUqVOn1KxZM02aNEkeHh6XvkcAAAC4phT6kn1efH19NX/+/Hy34+PjozFjxmjMmDGFqR4AAAD/QPyWPQAAAGx10Y99ArLihnAAAHAx6CEFAACArQikAAAAsBWBFAAAALYikAIAAMBWBFIAAADYikAKAAAAWxFIAQAAYCsCKQAAAGxFIAUAAICtCKQAAACwFYEUAAAAtiKQAgAAwFYEUgAAANiKQAoAAABbEUgBAABgKwIpAAAAbEUgBQAAgK0IpAAAALAVgRQAAAC2IpACAADAVp52NwC4XsQ8O8fuJlwRu/97h91NAABcY+ghBQAAgK0IpAAAALAVgRQAAAC2IpACAADAVgRSAAAA2IpACgAAAFsRSAEAAGArAikAAABsRSAFAACArQikAAAAsBWBFAAAALYikAIAAMBWBFIAAADYikAKAAAAWxFIAQAAYCtPuxsAACiYmGfn2N2Ey273f++wuwkAbEAPKQAAAGxFIAUAAICtuGQPAMB14Hq45UPito9rFT2kAAAAsBWBFAAAALYikAIAAMBWBFIAAADYikAKAAAAWxFIAQAAYCsCKQAAAGxFIAUAAICtCKQAAACwFYEUAAAAtipUIB06dKhuuukmBQYGqlSpUrrrrru0bds2tzLGGCUlJSkyMlK+vr6Ki4vT5s2b3cqkpaUpISFBYWFh8vf3V/v27fX7779f+t4AAADgmlOoQLps2TL17t1bK1eu1MKFC3Xu3Dm1bNlSJ06csMoMGzZMI0aM0NixY7V69Wq5XC61aNFCx44ds8okJiZq1qxZmj59ur777jsdP35cbdu2VXp6etHtGQAAAK4JnoUpPG/ePLfXEydOVKlSpbR27VrddtttMsZo1KhRGjBggDp06CBJ+uCDDxQeHq5p06bpkUce0ZEjRzRhwgRNnjxZzZs3lyRNmTJFUVFRWrRokVq1alVEuwYAAIBrwSXdQ3rkyBFJUkhIiCQpOTlZqampatmypVXG6XQqNjZWK1askCStXbtWZ8+edSsTGRmp6tWrW2WySktL09GjR90mAAAA/DNcdCA1xqhv37665ZZbVL16dUlSamqqJCk8PNytbHh4uLUsNTVV3t7eCg4OzrVMVkOHDlVQUJA1RUVFXWyzAQAAcJW56ED6+OOPa8OGDfroo4+yLXM4HG6vjTHZ5mWVV5nnnntOR44csaa9e/debLMBAABwlbmoQJqQkKAvv/xS33zzjUqXLm3Nd7lckpStp3P//v1Wr6nL5dKZM2d06NChXMtk5XQ6Vbx4cbcJAAAA/wyFCqTGGD3++OP67LPPtGTJEpUtW9ZtedmyZeVyubRw4UJr3pkzZ7Rs2TI1atRIklS3bl15eXm5lUlJSdGmTZusMgAAALh+FGqUfe/evTVt2jR98cUXCgwMtHpCg4KC5OvrK4fDocTERA0ZMkQVK1ZUxYoVNWTIEPn5+alLly5W2e7du+upp55SaGioQkJC1K9fP9WoUcMadQ8AAIDrR6EC6bhx4yRJcXFxbvMnTpyo+Ph4SVL//v116tQp9erVS4cOHVL9+vW1YMECBQYGWuVHjhwpT09PdezYUadOnVKzZs00adIkeXh4XNreAAAA4JpTqEBqjMm3jMPhUFJSkpKSknIt4+PjozFjxmjMmDGFqR4AAAD/QPyWPQAAAGxFIAUAAICtCKQAAACwFYEUAAAAtiKQAgAAwFYEUgAAANiKQAoAAABbEUgBAABgKwIpAAAAbEUgBQAAgK0IpAAAALAVgRQAAAC2IpACAADAVp52NwAAJCnm2Tl2N+GK2P3fO+xuAgBcdeghBQAAgK0IpAAAALAVgRQAAAC2IpACAADAVgRSAAAA2IpACgAAAFsRSAEAAGArAikAAABsRSAFAACArQikAAAAsBWBFAAAALYikAIAAMBWBFIAAADYikAKAAAAWxFIAQAAYCsCKQAAAGxFIAUAAICtCKQAAACwFYEUAAAAtiKQAgAAwFYEUgAAANiKQAoAAABbEUgBAABgKwIpAAAAbEUgBQAAgK0IpAAAALAVgRQAAAC2IpACAADAVgRSAAAA2IpACgAAAFsRSAEAAGArAikAAABsRSAFAACArQikAAAAsBWBFAAAALYikAIAAMBWBFIAAADYqtCB9Ntvv1W7du0UGRkph8Ohzz//3G15fHy8HA6H29SgQQO3MmlpaUpISFBYWJj8/f3Vvn17/f7775e0IwAAALg2FTqQnjhxQrVq1dLYsWNzLXP77bcrJSXFmubOneu2PDExUbNmzdL06dP13Xff6fjx42rbtq3S09MLvwcAAAC4pnkWdoXWrVurdevWeZZxOp1yuVw5Ljty5IgmTJigyZMnq3nz5pKkKVOmKCoqSosWLVKrVq0K2yQAAABcwy7LPaRLly5VqVKlVKlSJfXs2VP79++3lq1du1Znz55Vy5YtrXmRkZGqXr26VqxYcTmaAwAAgKtYoXtI89O6dWvde++9io6OVnJysl588UU1bdpUa9euldPpVGpqqry9vRUcHOy2Xnh4uFJTU3PcZlpamtLS0qzXR48eLepmAwAAwCZFHkg7depk/bt69eqqV6+eoqOjNWfOHHXo0CHX9YwxcjgcOS4bOnSoBg8eXNRNBQAAwFXgsj/2KSIiQtHR0dqxY4ckyeVy6cyZMzp06JBbuf379ys8PDzHbTz33HM6cuSINe3du/dyNxsAAABXyGUPpAcPHtTevXsVEREhSapbt668vLy0cOFCq0xKSoo2bdqkRo0a5bgNp9Op4sWLu00AAAD4Zyj0Jfvjx49r586d1uvk5GStX79eISEhCgkJUVJSku655x5FRERo9+7dev755xUWFqa7775bkhQUFKTu3bvrqaeeUmhoqEJCQtSvXz/VqFHDGnUPAACA60ehA+maNWvUpEkT63Xfvn0lSd26ddO4ceO0ceNGffjhhzp8+LAiIiLUpEkTzZgxQ4GBgdY6I0eOlKenpzp27KhTp06pWbNmmjRpkjw8PIpglwAAAHAtKXQgjYuLkzEm1+Xz58/Pdxs+Pj4aM2aMxowZU9jqAQAA8A/Db9kDAADAVgRSAAAA2IpACgAAAFsRSAEAAGArAikAAABsRSAFAACArQikAAAAsBWBFAAAALYikAIAAMBWBFIAAADYikAKAAAAWxFIAQAAYCsCKQAAAGxFIAUAAICtCKQAAACwFYEUAAAAtiKQAgAAwFYEUgAAANiKQAoAAABbEUgBAABgKwIpAAAAbEUgBQAAgK0IpAAAALAVgRQAAAC2IpACAADAVgRSAAAA2IpACgAAAFsRSAEAAGArAikAAABsRSAFAACArQikAAAAsBWBFAAAALYikAIAAMBWBFIAAADYytPuBlxLdvt0sbsJV8ARuxsAAACuM/SQAgAAwFb0kKLIXB89yBK9yAAAFC16SAEAAGArAikAAABsxSV7AMA/ArcNAdcuekgBAABgKwIpAAAAbEUgBQAAgK0IpAAAALAVgRQAAAC2IpACAADAVgRSAAAA2IrnkAIAgOsez7G1Fz2kAAAAsBWBFAAAALYikAIAAMBWBFIAAADYqtCB9Ntvv1W7du0UGRkph8Ohzz//3G25MUZJSUmKjIyUr6+v4uLitHnzZrcyaWlpSkhIUFhYmPz9/dW+fXv9/vvvl7QjAAAAuDYVOpCeOHFCtWrV0tixY3NcPmzYMI0YMUJjx47V6tWr5XK51KJFCx07dswqk5iYqFmzZmn69On67rvvdPz4cbVt21bp6ekXvycAAAC4JhX6sU+tW7dW69atc1xmjNGoUaM0YMAAdejQQZL0wQcfKDw8XNOmTdMjjzyiI0eOaMKECZo8ebKaN28uSZoyZYqioqK0aNEitWrV6hJ2BwAAANeaIn0OaXJyslJTU9WyZUtrntPpVGxsrFasWKFHHnlEa9eu1dmzZ93KREZGqnr16lqxYgWBFP9YPOMOAICcFWkgTU1NlSSFh4e7zQ8PD9dvv/1mlfH29lZwcHC2MpnrZ5WWlqa0tDTr9dGjR4uy2QAAALDRZRll73A43F4bY7LNyyqvMkOHDlVQUJA1RUVFFVlbAQAAYK8iDaQul0uSsvV07t+/3+o1dblcOnPmjA4dOpRrmayee+45HTlyxJr27t1blM0GAACAjYo0kJYtW1Yul0sLFy605p05c0bLli1To0aNJEl169aVl5eXW5mUlBRt2rTJKpOV0+lU8eLF3SYAAAD8MxT6HtLjx49r586d1uvk5GStX79eISEhKlOmjBITEzVkyBBVrFhRFStW1JAhQ+Tn56cuXc4P6AgKClL37t311FNPKTQ0VCEhIerXr59q1KhhjboHAADA9aPQgXTNmjVq0qSJ9bpv376SpG7dumnSpEnq37+/Tp06pV69eunQoUOqX7++FixYoMDAQGudkSNHytPTUx07dtSpU6fUrFkzTZo0SR4eHkWwSwAAALiWFDqQxsXFyRiT63KHw6GkpCQlJSXlWsbHx0djxozRmDFjCls9AAAA/mH4LXsAAADYqkifQwoAuHyujx9X4IcVgOsRPaQAAACwFYEUAAAAtiKQAgAAwFYEUgAAANiKQAoAAABbEUgBAABgKwIpAAAAbEUgBQAAgK0IpAAAALAVgRQAAAC2IpACAADAVgRSAAAA2IpACgAAAFsRSAEAAGArAikAAABsRSAFAACArQikAAAAsJWn3Q0AAACX326fLnY34Qo5YncDcBHoIQUAAICtCKQAAACwFYEUAAAAtiKQAgAAwFYMagJwVWDABQBcv+ghBQAAgK0IpAAAALAVgRQAAAC2IpACAADAVgRSAAAA2IpACgAAAFsRSAEAAGArAikAAABsRSAFAACArQikAAAAsBWBFAAAALYikAIAAMBWBFIAAADYikAKAAAAWxFIAQAAYCsCKQAAAGxFIAUAAICtCKQAAACwFYEUAAAAtiKQAgAAwFYEUgAAANiKQAoAAABbEUgBAABgKwIpAAAAbEUgBQAAgK0IpAAAALAVgRQAAAC2KvJAmpSUJIfD4Ta5XC5ruTFGSUlJioyMlK+vr+Li4rR58+aibgYAAACuEZelh/Rf//qXUlJSrGnjxo3WsmHDhmnEiBEaO3asVq9eLZfLpRYtWujYsWOXoykAAAC4yl2WQOrp6SmXy2VNJUuWlHS+d3TUqFEaMGCAOnTooOrVq+uDDz7QyZMnNW3atMvRFAAAAFzlLksg3bFjhyIjI1W2bFl17txZv/76qyQpOTlZqampatmypVXW6XQqNjZWK1asyHV7aWlpOnr0qNsEAACAf4YiD6T169fXhx9+qPnz52v8+PFKTU1Vo0aNdPDgQaWmpkqSwsPD3dYJDw+3luVk6NChCgoKsqaoqKiibjYAAABsUuSBtHXr1rrnnntUo0YNNW/eXHPmzJEkffDBB1YZh8Phto4xJtu8Cz333HM6cuSINe3du7eomw0AAACbXPbHPvn7+6tGjRrasWOHNdo+a2/o/v37s/WaXsjpdKp48eJuEwAAAP4ZLnsgTUtL09atWxUREaGyZcvK5XJp4cKF1vIzZ85o2bJlatSo0eVuCgAAAK5CnkW9wX79+qldu3YqU6aM9u/fr1deeUVHjx5Vt27d5HA4lJiYqCFDhqhixYqqWLGihgwZIj8/P3Xp0qWomwIAAIBrQJEH0t9//1333XefDhw4oJIlS6pBgwZauXKloqOjJUn9+/fXqVOn1KtXLx06dEj169fXggULFBgYWNRNAQAAwDWgyAPp9OnT81zucDiUlJSkpKSkoq4aAAAA1yB+yx4AAAC2IpACAADAVgRSAAAA2IpACgAAAFsRSAEAAGArAikAAABsRSAFAACArQikAAAAsBWBFAAAALYikAIAAMBWBFIAAADYikAKAAAAWxFIAQAAYCsCKQAAAGxFIAUAAICtCKQAAACwFYEUAAAAtiKQAgAAwFYEUgAAANiKQAoAAABbEUgBAABgKwIpAAAAbEUgBQAAgK0IpAAAALAVgRQAAAC2IpACAADAVgRSAAAA2IpACgAAAFsRSAEAAGArAikAAABsRSAFAACArQikAAAAsBWBFAAAALYikAIAAMBWBFIAAADYikAKAAAAWxFIAQAAYCsCKQAAAGxFIAUAAICtCKQAAACwFYEUAAAAtiKQAgAAwFYEUgAAANiKQAoAAABbEUgBAABgKwIpAAAAbEUgBQAAgK0IpAAAALAVgRQAAAC2IpACAADAVgRSAAAA2IpACgAAAFvZGkjffvttlS1bVj4+Pqpbt66WL19uZ3MAAABgA9sC6YwZM5SYmKgBAwZo3bp1uvXWW9W6dWvt2bPHriYBAADABrYF0hEjRqh79+7q0aOHqlatqlGjRikqKkrjxo2zq0kAAACwgacdlZ45c0Zr167Vs88+6za/ZcuWWrFiRbbyaWlpSktLs14fOXJEknT06NHL29BsDTFXtj47XMoxvR6Oj3Txx4jjkzeOT/6uh2PE8ckfn7G8cXzydgWzU2ZOM6YAx9bYYN++fUaS+f77793mv/rqq6ZSpUrZyg8aNMhIYmJiYmJiYmJiusamvXv35psNbekhzeRwONxeG2OyzZOk5557Tn379rVeZ2Rk6O+//1ZoaGiO5f8Jjh49qqioKO3du1fFixe3uzlXJY5R3jg+eeP45I3jkz+OUd44Pnm7Ho6PMUbHjh1TZGRkvmVtCaRhYWHy8PBQamqq2/z9+/crPDw8W3mn0ymn0+k2r0SJEpeziVeN4sWL/2NP1KLCMcobxydvHJ+8cXzyxzHKG8cnb//04xMUFFSgcrYMavL29lbdunW1cOFCt/kLFy5Uo0aN7GgSAAAAbGLbJfu+ffuqa9euqlevnho2bKh3331Xe/bs0aOPPmpXkwAAAGAD2wJpp06ddPDgQb300ktKSUlR9erVNXfuXEVHR9vVpKuK0+nUoEGDst2qgP/DMcobxydvHJ+8cXzyxzHKG8cnbxwfdw5jCjIWHwAAALg8+C17AAAA2IpACgAAAFsRSAEAAGArAilwlTHG6OGHH1ZISIgcDofWr19vd5OumLi4OCUmJua63OFw6PPPPy/w9pYuXSqHw6HDhw9fctuulPyOQWHkd7x27959xc6xK1nXtYzjdHWJj4/XXXfdZb3O+vmMiYnRqFGjLqmOrN9TkyZNyvdZ60lJSapdu3au7bwWXZeBdO/everevbsiIyPl7e2t6OhoPfHEEzp48KDdTbPF9fgFWBRfIpfLvHnzNGnSJM2ePdt6AsWVdrWeEykpKWrdurXdzbisPvvsM7388stFsq2r6XhFRUW5nc/X4h8LhXGx+5f1OF1NrnToKer6ivKPvaLUqFEjpaSkFPgB8jkZPXq0Jk2aVHSNsoGtPx1qh19//VUNGzZUpUqV9NFHH6ls2bLavHmznn76aX399ddauXKlQkJC7G7mVenMmTPy9va2uxn/eLt27VJERMRF/0iEMUbp6eny9PznfbxdLpfdTbjsivL752o6Xh4eHldVe65W/4TjdPbsWXl5edndjGuGt7f3Jb/nlxJmrxbXXQ9p79695e3trQULFig2NlZlypRR69attWjRIu3bt08DBgyQdL4H7eWXX1aXLl0UEBCgyMhIjRkzxm1bR44c0cMPP6xSpUqpePHiatq0qX7++WdreWaX+uTJkxUTE6OgoCB17txZx44ds8pkZGTotddeU4UKFeR0OlWmTBm9+uqr1vKNGzeqadOm8vX1VWhoqB5++GEdP37cWp7TX3x33XWX4uPjrdcxMTEaMmSIHnroIQUGBqpMmTJ69913reVly5aVJN14441yOByKi4uT9H9/nQ4dOlSRkZGqVKmSXnrpJdWoUSPbca1bt64GDhxYwHch/33Pb79Xr16tFi1aKCwsTEFBQYqNjdVPP/3ktv2kpCSVKVNGTqdTkZGR6tOnj3XMfvvtNz355JNyOBxyOByFavflFB8fr4SEBO3Zs0cOh0MxMTFKS0tTnz59VKpUKfn4+OiWW27R6tWrrXUye2Lmz5+vevXqyel0avny5TLGaNiwYSpXrpx8fX1Vq1Ytffrpp9Z6hw4d0v3336+SJUvK19dXFStW1MSJEyXlfk5cCRkZGerfv79CQkLkcrmUlJRkLct6CXrFihWqXbu2fHx8VK9ePX3++ec59uyuXbtW9erVk5+fnxo1aqRt27ZJOv8Z9vDw0Nq1ayWdD/MhISG66aabrHU/+ugjRUREWK+feeYZVapUSX5+fipXrpxefPFFnT17VtL5nuVixYppzZo1bvWPGTNG0dHRKshT9i78TOf32T1z5owef/xxRUREyMfHRzExMRo6dGiux2vVqlW68cYbreO1bt26bPVv2bJFbdq0UUBAgMLDw9W1a1cdOHAg33ZLeX+mL+x13717t5o0aSJJCg4OlsPhUHx8vD788EOFhoYqLS3Nbbv33HOP/vOf/+R6vBISEpSYmKjg4GCFh4fr3Xff1YkTJ/Tggw8qMDBQ5cuX19dff22ts2zZMt18881yOp2KiIjQs88+q3PnzlnLc7qCUrt27Wzn4nvvvae7775bfn5+qlixor788ktrX3PaP+n8FZBbbrlFJUqUUGhoqNq2batdu3ZZ2816dSLz87148eIcz+HL4dNPP1WNGjWs79/mzZvr6aef1gcffKAvvvjC+t5cunSp1d6PP/5YcXFx8vHx0ZQpUyRJEydOVNWqVeXj46MqVaro7bffdqtn37596tSpk4KDgxUaGqo777xTu3fvlnT++zun+i5WfHy8li1bptGjR1vb27Vrl7p3766yZcvK19dXlStX1ujRowu97WPHjuWaFXK62nT48GG3/SlIb/p///tfhYeHKzAwUN27d9fp06ez7V/WWwv69OmT63epJP3yyy+65ZZb5OPjo2rVqmnRokWFvi2qSJnryMGDB43D4TBDhgzJcXnPnj1NcHCwycjIMNHR0SYwMNAMHTrUbNu2zbz55pvGw8PDLFiwwBhjTEZGhmncuLFp166dWb16tdm+fbt56qmnTGhoqDl48KAxxphBgwaZgIAA06FDB7Nx40bz7bffGpfLZZ5//nmrzv79+5vg4GAzadIks3PnTrN8+XIzfvx4Y4wxJ06cMJGRkdb6ixcvNmXLljXdunWz1o+NjTVPPPGE237ceeedbmWio6NNSEiIeeutt8yOHTvM0KFDTbFixczWrVuNMcasWrXKSDKLFi0yKSkpVvu7detmAgICTNeuXc2mTZvMxo0bzd69e02xYsXMqlWrrO3//PPPxuFwmF27dhXq/cht3wuy34sXLzaTJ082W7ZsMVu2bDHdu3c34eHh5ujRo8YYYz755BNTvHhxM3fuXPPbb7+ZH3/80bz77rvGmPPnQenSpc1LL71kUlJSTEpKSqHafTkdPnzYvPTSS6Z06dImJSXF7N+/3/Tp08dERkaauXPnms2bN5tu3bqZ4OBg63365ptvjCRTs2ZNs2DBArNz505z4MAB8/zzz5sqVaqYefPmmV27dpmJEycap9Npli5daowxpnfv3qZ27dpm9erVJjk52SxcuNB8+eWXxpjcz4nLLTY21hQvXtwkJSWZ7du3mw8++MA4HA7rcyfJzJo1yxhjzNGjR01ISIh54IEHzObNm83cuXNNpUqVjCSzbt06t2NTv359s3TpUrN582Zz6623mkaNGll11qlTx7zxxhvGGGPWr19vgoODjbe3tzly5IgxxpiHH37YdOrUySr/8ssvm++//94kJyebL7/80oSHh5vXXnvNWt6iRQvTq1cvt/268cYbzcCBAwt8DDI/0/l9dl9//XUTFRVlvv32W7N7926zfPlyM23aNGtbFx6v48ePm5IlS5pOnTqZTZs2ma+++sqUK1fO7Xj98ccfJiwszDz33HNm69at5qeffjItWrQwTZo0KVDb8/o+S05Otuo6d+6cmTlzppFktm3bZlJSUszhw4fNyZMnTVBQkPn444+tbf7111/G29vbLFmyJNfjFRgYaF5++WWzfft28/LLL5tixYqZ1q1bm3fffdds377dPPbYYyY0NNScOHHC/P7778bPz8/06tXLbN261cyaNcuEhYWZQYMGWduMjo42I0eOdKunVq1abmUkmdKlS5tp06aZHTt2mD59+piAgABz8ODBXPfPGGM+/fRTM3PmTLN9+3azbt06065dO1OjRg2Tnp6e7TgZU7BzuCj98ccfxtPT04wYMcIkJyebDRs2mLfeesscO3bMdOzY0dx+++3W92ZaWprV3piYGDNz5kzz66+/mn379pl3333XREREWPNmzpxpQkJCzKRJk4wx5/9/q1ixonnooYfMhg0bzJYtW0yXLl1M5cqVTVpaWq71XazDhw+bhg0bmp49e1rbO336tBk4cKBZtWqV+fXXX82UKVOMn5+fmTFjhrVet27dzJ133mm9zvp/bn5ZIev7aYwxhw4dMpLMN998Y4z5v/f40KFDxhhjJk6caIKCgqzyM2bMMN7e3mb8+PHml19+MQMGDDCBgYGmVq1aebYzr+/S9PR0U7lyZdOiRQuzfv16s3z5cnPzzTe7fWdcaddVIF25cmWeB3vEiBFGkvnzzz9NdHS0uf32292Wd+rUybRu3doYcz4QFS9e3Jw+fdqtTPny5c3//vc/Y8z5QOrn52eFJGOMefrpp039+vWNMef/Q3U6ndYXdlbvvvuuCQ4ONsePH7fmzZkzxxQrVsykpqYaYwoeSB944AHrdUZGhilVqpQZN26cMSbnD4wx50/w8PDwbF8CrVu3No899pj1OjEx0cTFxeW4D7nJa98Lst9ZnTt3zgQGBpqvvvrKGGPM8OHDTaVKlcyZM2dyLJ/TfzhXi5EjR5ro6GhjzPkQ4eXlZaZOnWotP3PmjImMjDTDhg0zxvzfl9nnn39ulTl+/Ljx8fExK1ascNt29+7dzX333WeMMaZdu3bmwQcfzLENuZ0Tl1tsbKy55ZZb3ObddNNN5plnnjHGuAescePGmdDQUHPq1Cmr7Pjx43P8z3zRokVWmTlz5hhJ1np9+/Y1bdu2NcYYM2rUKPPvf//b1KlTx8yZM8cYY0ylSpWsz0pOhg0bZurWrWu9njFjhgkODra+G9avX28cDodJTk4u8DG4MJDm9dlNSEgwTZs2NRkZGTlu68Lj9b///c+EhISYEydOWMvHjRvndrxefPFF07JlS7dt7N271wpWecnv+yy3oJX5n3Cmxx57zPqeNeb8e1KuXLlc9zHrOXPu3Dnj7+9vunbtas1LSUkxkswPP/xgnn/+eVO5cmW37b311lsmICDACoUFDaQvvPCC9fr48ePG4XCYr7/+Os/9y2r//v1Gktm4cWOexymvc7gorV271kgyu3fvzrYsa+i5sL2jRo1ymx8VFeX2x5Ex5/+Ya9iwoTHGmAkTJmR7H9LS0oyvr6+ZP39+rvVdipz+v8yqV69e5p577rFeFySQ5pUViiKQNmzY0Dz66KNuddSvXz/fQJrXd+nXX39tPD093TpkFi5caGsgve4u2efF/P/LaZmXcBs2bOi2vGHDhtq6dauk85cAjx8/rtDQUAUEBFhTcnKy2+WXmJgYBQYGWq8jIiK0f/9+SdLWrVuVlpamZs2a5dierVu3qlatWvL397fmNW7cWBkZGYW+XFOzZk3r3w6HQy6Xy2pHXmrUqJHtvtGePXvqo48+0unTp3X27FlNnTpVDz30UKHak9e+F2S/9+/fr0cffVSVKlVSUFCQgoKCdPz4ce3Zs0eSdO+99+rUqVMqV66cevbsqVmzZrldkrtW7Nq1S2fPnlXjxo2teV5eXrr55putczFTvXr1rH9v2bJFp0+fVosWLdzOzw8//NA6Px977DFNnz5dtWvXVv/+/bVixYors1P5uPBcldw/Mxfatm2batasKR8fH2vezTffnO82My+/Z24zLi5Oy5cvV0ZGhpYtW6a4uDjFxcVp2bJlSk1N1fbt2xUbG2ut/+mnn+qWW26Ry+VSQECAXnzxReu8k87fMuPp6alZs2ZJkt5//301adJEMTExhTwS2due9bMbHx+v9evXq3LlyurTp48WLFiQ63YyP1d+fn7WvKzfcWvXrtU333zjds5UqVJFkty+13Lbfl7fZwXVs2dPLViwQPv27ZN0/rJvfHx8nrfWXHiMPDw8FBoa6nZrUXh4uKTz7/nWrVvVsGFDt+01btxYx48f1++//16otl5Yr7+/vwIDA/P9Xt21a5e6dOmicuXKqXjx4tbtMReeQ/nVlfUcLkq1atVSs2bNVKNGDd17770aP368Dh06lO96F37//PXXX9bg4QvPpVdeecU6j9auXaudO3cqMDDQWh4SEqLTp0/ne64VpXfeeUf16tVTyZIlFRAQoPHjx+f7XmSVV1YoCpnnbF515iSv79Jt27YpKirK7d7V3L4/r5R/3qiHPFSoUEEOh0NbtmzJceTeL7/8ouDgYIWFheW6jcwvsYyMDEVEROR4T8uFj2vIemO3w+FQRkaGJMnX1zfP9hpjcv0SzpxfrFixbPelZd7PdqG82pGXC0Nhpnbt2snpdGrWrFlyOp1KS0vTPffck++2LpTXvhdkv+Pj4/XXX39p1KhRio6OltPpVMOGDXXmzBlJ50eqbtu2TQsXLtSiRYvUq1cvvf7661q2bNk1dbN91j+SLpyfdd6F71XmeztnzhzdcMMNbuUyfze5devW+u233zRnzhwtWrRIzZo1U+/evfXGG28U+X4URkHP1ZyOQdbPQk7bvPAzLEm33Xabjh07pp9++knLly/Xyy+/rKioKA0ZMkS1a9dWqVKlVLVqVUnSypUr1blzZw0ePFitWrVSUFCQpk+fruHDh1vb9/b2VteuXTVx4kR16NBB06ZNu6QnOuR1POrUqaPk5GR9/fXXWrRokTp27KjmzZu73Suc37G5UEZGhtq1a6fXXnst27IL76PNSX7fZwV14403qlatWvrwww/VqlUrbdy4UV999VWe6+R0jHJ7z/M6b67E92q7du0UFRWl8ePHKzIyUhkZGapevbr13ZWbvM7houTh4aGFCxdqxYoVWrBggcaMGaMBAwboxx9/zHO9nL5/xo8fr/r162fbfmaZunXraurUqdm2VbJkyUvdjQL5+OOP9eSTT2r48OFq2LChAgMD9frrr+e7rwVx4bkkuX/+cjqXLoe8zs+8/p+1y3XVQxoaGqoWLVro7bff1qlTp9yWpaamaurUqerUqZP1Jq1cudKtzMqVK63egjp16ig1NVWenp6qUKGC25RXoL1QxYoV5evrq8WLF+e4vFq1alq/fr1OnDhhzfv+++9VrFgxVapUSdL5D25KSoq1PD09XZs2bSpQ/Zkye0DT09MLVN7T01PdunXTxIkTNXHiRHXu3Nmt16Ug8tr3guz38uXL1adPH7Vp00b/+te/5HQ6sw288PX1Vfv27fXmm29q6dKl+uGHH7Rx40Zrnwu6v3aqUKGCvL299d1331nzzp49qzVr1lghKSfVqlWT0+nUnj17sp2fUVFRVrmSJUsqPj5eU6ZM0ahRo6wBM4U9J+xQpUoVbdiwwW0ATNbBRAURFBSk2rVra+zYsXI4HKpWrZpuvfVWrVu3TrNnz3brHf3+++8VHR2tAQMGqF69eqpYsaJ+++23bNvs0aOHFi1apLfffltnz55Vhw4dLm4nC6B48eLq1KmTxo8frxkzZmjmzJn6+++/s5WrVq2afv75Z7fvvqzfcXXq1NHmzZsVExOT7bzJ6Y/TC+X3fZZVXudYjx49NHHiRL3//vtq3ry52zl7qapVq6YVK1a4BYQVK1YoMDDQ+uMt6/fq0aNHlZycXKh6ctq/gwcPauvWrXrhhRfUrFkzVa1atUC9j1eaw+FQ48aNNXjwYK1bt07e3t6aNWtWgb83w8PDdcMNN+jXX3/Ndh5l9gjXqVNHO3bsUKlSpbKVyRwxXtTf01m3t3z5cjVq1Ei9evXSjTfeqAoVKlxU72xeWSEzXF94PhX2cXpVq1bNsY5LUaVKFe3Zs0d//vmnNe/CwbJ2uK4CqSSNHTtWaWlpatWqlb799lvt3btX8+bNU4sWLXTDDTe4jXD//vvvNWzYMG3fvl1vvfWWPvnkEz3xxBOSpObNm6thw4a66667NH/+fO3evVsrVqzQCy+8UOD/FH18fPTMM8+of//+1qXUlStXasKECZKk+++/Xz4+PurWrZs2bdqkb775RgkJCeratat1Capp06aaM2eO5syZo19++UW9evUq9HPvSpUqJV9fX82bN09//vmnjhw5ku86PXr00JIlS/T1118X+nJ9fvtekP2uUKGCJk+erK1bt+rHH3/U/fff79ZDM2nSJE2YMEGbNm3Sr7/+qsmTJ8vX11fR0dGSzt9K8e2332rfvn0FHkFsB39/fz322GN6+umnNW/ePG3ZskU9e/bUyZMn1b1791zXCwwMVL9+/fTkk0/qgw8+0K5du7Ru3Tq99dZb+uCDDyRJAwcO1BdffKGdO3dq8+bNmj17thVyL+acuNK6dOmijIwMPfzww9q6davmz59v9e4W9i//uLg4TZkyRbGxsXI4HAoODla1atU0Y8YMtycMVKhQQXv27NH06dO1a9cuvfnmm9al+QtVrVpVDRo00DPPPKP77ruvyHoPsxo5cqSmT5+uX375Rdu3b9cnn3wil8uV40O1u3TpomLFiql79+7asmWL5s6dm603vHfv3vr777913333adWqVfr111+1YMECPfTQQ/kGg/y+z7KKjo6Ww+HQ7Nmz9ddff7k9ReP+++/Xvn37NH78+Iv6fslLr169tHfvXiUkJOiXX37RF198oUGDBqlv375Wb1bTpk01efJkLV++XJs2bVK3bt2snr2Cymn/MkeTv/vuu9q5c6eWLFmivn37Fun+Xaoff/xRQ4YM0Zo1a7Rnzx599tln+uuvv1S1alXFxMRow4YN2rZtmw4cOJBnT19SUpKGDh2q0aNHa/v27dq4caMmTpyoESNGSDr/HoeFhenOO+/U8uXLlZycrGXLlumJJ56wbp0oTH0FERMTox9//FG7d+/WgQMHVKFCBa1Zs0bz58/X9u3b9eKLL15UKMsrK/j6+qpBgwb673//qy1btujbb7/VCy+8UKjtP/HEE3r//ff1/vvva/v27Ro0aJA2b95c6HZeqEWLFipfvry6deumDRs26Pvvv7eeMmRbz6kN963abvfu3SY+Pt64XC7j5eVloqKiTEJCgjlw4IBVJjo62gwePNh07NjR+Pn5mfDw8Gw3bR89etQkJCSYyMhIazv333+/2bNnjzHm/KCmC286NsZ9wIox50e6vfLKKyY6Otp4eXmZMmXKuD0FYMOGDaZJkybGx8fHhISEmJ49e5pjx45Zy8+cOWMee+wxExISYkqVKmWGDh2a46Cm/G7QHz9+vImKijLFihUzsbGxxpj8byi/9dZbTbVq1XJdnp+89j2//f7pp59MvXr1jNPpNBUrVjSffPKJ237OmjXL1K9f3xQvXtz4+/ubBg0auA0K+OGHH0zNmjWN0+k0V9vHIOs5curUKZOQkGDCwsKM0+k0jRs3dnvKQW6DJzIyMszo0aNN5cqVjZeXlylZsqRp1aqVWbZsmTHm/ACDqlWrGl9fXxMSEmLuvPNO8+uvv1rr53ROXG75DdJTlhvuv//+e1OzZk3j7e1t6tata6ZNm2YkmV9++cUYk/OxWbdunZHkNsjoq6++MpLM2LFjrXlPPPGEkWQ2bdrk1p6nn37ahIaGmoCAANOpUyczcuRItwEImSZMmGAkub1XhT0G+X123333XVO7dm3j7+9vihcvbpo1a2Z++uknq2zW4/XDDz+YWrVqGW9vb1O7dm1rJPiFAy62b99u7r77blOiRAnj6+trqlSpYhITE3MdVHShvD7TOQ3ueOmll4zL5TIOh8PtO8sYY7p27WpCQkKyDRzN63hlyum4XXgsli5dam666Sbj7e1tXC6XeeaZZ8zZs2etskeOHDEdO3Y0xYsXN1FRUWbSpEk5DmrKOvgjKCjITJw4Mc/9W7hwoalatapxOp2mZs2aZunSpW7bKsjgr5zO4aKyZcsW06pVK1OyZEnjdDpNpUqVzJgxY4wx5wdgtWjRwgQEBFiDcvIaADl16lRTu3Zt4+3tbYKDg81tt91mPvvsM2t5SkqK+c9//mN9t5UrV8707NnTesJFTvVdim3btpkGDRoYX19f63siPj7eBAUFmRIlSpjHHnvMPPvss/kOFso6qCm/rLBlyxar3tq1a5sFCxYUalCTMca8+uqrJiwszAQEBJhu3bqZ/v37F6qdxmQf8Lx161bTuHFj4+3tbapUqWJ9D86bN6+AR7RoOYwpwI1F16GYmBglJiZelb/qcDUwxqhKlSp65JFHrrq/8HH9mjp1qh588EEdOXLksvVKFtSrr76q6dOnW7eJoHBatGihqlWr6s0337S7KcB14fvvv9ctt9yinTt3qnz58le8/utqUBOKxv79+zV58mTt27dPDz74oN3NwXXsww8/VLly5XTDDTfo559/1jPPPKOOHTvaGkaPHz+urVu3asyYMUX2E6DXk7///lsLFizQkiVLNHbsWLubA/xjzZo1SwEBAapYsaJ27typJ554Qo0bN7YljEoEUlyE8PBwhYWF6d1331VwcLDdzcF1LDU1VQMHDlRqaqoiIiJ07733ut0HbofHH39cH330ke66664iv//RTnv27FG1atVyXb5lyxaVKVPmkuupU6eODh06pNdee02VK1e+5O0ByNmxY8fUv39/7d27V2FhYWrevLnbE0OuNC7ZAwDyde7cOetnHXMSExMjT0/6OABcHAIpAAAAbHXdPfYJAAAAVxcCKQAAAGxFIAUAAICtCKQAAACwFYEUAAAAtiKQAgAAwFYEUgAAANiKQAoAAABb/T/iYwPMvmu1GwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_labels = np.unique(train_labels + test_labels)\n",
    "train_count = [np.sum(np.array(train_labels) == lab) for lab in unique_labels]\n",
    "test_count = [np.sum(np.array(test_labels) == lab) for lab in unique_labels]\n",
    "\n",
    "\n",
    "# distribution of the training and test set\n",
    "def plot_distribution(train_count, test_count, unique_labels):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.title(\"Distribution of the training and test set\")\n",
    "    plt.bar(unique_labels, train_count, label=\"Training Set\")\n",
    "    plt.bar(unique_labels, test_count, label=\"Test Set\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_distribution(train_count, test_count, unique_labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: EXPLANATION\n",
    "To check if a dataset is unbalanced, we can calculate the proportion of each class in the dataset and compare the proportions. If the proportions of the classes are significantly different, then the dataset is likely to be unbalanced.\n",
    "In this case, the dataset is balanced"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KAZE:\n",
    "    def __init__(self, threshold=0.001):\n",
    "        self.extractor = cv2.KAZE_create(threshold=threshold)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class AKAZE:\n",
    "    def __init__(self, threshold=0.001):\n",
    "        self.extractor = cv2.AKAZE_create(threshold=threshold)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class SIFT:\n",
    "    def __init__(self, n_features=300):\n",
    "        self.extractor = cv2.SIFT_create(nfeatures=n_features)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class DenseSIFT:\n",
    "    def __init__(self, n_features=300, step_size=10, patch_size=10):\n",
    "        self.extractor = cv2.SIFT_create(nfeatures=n_features)\n",
    "        self.step_div_size = step_size\n",
    "        self.num_sizes = patch_size\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        descriptors = []\n",
    "        init_step_size_x = max(image.shape[1] // self.step_div_size, 16)\n",
    "        init_step_size_y = max(image.shape[0] // self.step_div_size, 16)\n",
    "        \n",
    "        for i in range(1, self.num_sizes+1):\n",
    "            current_step_x = init_step_size_x * i\n",
    "            current_step_y = init_step_size_y * i\n",
    "            avg_size = (current_step_x + current_step_y) // 2\n",
    "            descriptors += [cv2.KeyPoint(x, y, avg_size) for y in range(0, image.shape[0], current_step_y) \n",
    "                                                    for x in range(0, image.shape[1], current_step_x)]\n",
    "        descriptors = self.extractor.compute(image, descriptors)[1]\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class ORB:\n",
    "    def __init__(self, n_features=100):\n",
    "        self.extractor = cv2.ORB_create(nfeatures=n_features)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class BRISK:\n",
    "    def __init__(self, n_features=100):\n",
    "        self.extractor = cv2.BRISK_create(nfeatures=n_features)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractors = {\n",
    "    \"SIFT\": SIFT,\n",
    "    \"DenseSIFT\": DenseSIFT,\n",
    "    \"KAZE\": KAZE,\n",
    "    \"AKAZE\": AKAZE,\n",
    "    \"ORB\": ORB,\n",
    "    \"BRISK\": BRISK\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images_filenames, train_labels, feature_extractor, extract_features=True):\n",
    "    descriptors = list()\n",
    "    label_per_descriptor = list()\n",
    "    images = list()\n",
    "\n",
    "    for filename, labels in zip(train_images_filenames, train_labels):\n",
    "        ima = cv2.imread(filename)\n",
    "        gray = cv2.cvtColor(ima, cv2.COLOR_BGR2GRAY)\n",
    "        if extract_features:\n",
    "            des = feature_extractor.extract_features(gray)\n",
    "            descriptors.append(des)\n",
    "        else:\n",
    "            images.append(gray)\n",
    "        label_per_descriptor.append(labels)\n",
    "    if not extract_features:\n",
    "        return images, label_per_descriptor\n",
    "    else:\n",
    "        return descriptors, label_per_descriptor\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. bag of visual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_local_features(features, n_clusters):\n",
    "    codebook = MiniBatchKMeans(n_clusters=n_clusters, verbose=False, batch_size=n_clusters *\n",
    "                               20, compute_labels=False, reassignment_ratio=10**-4, random_state=42)\n",
    "    codebook.fit(features)\n",
    "    return codebook\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCRIPTOR = feature_extractors[\"SIFT\"]()\n",
    "train_descriptors, train_labels_descrip = extract_features(\n",
    "    train_images_filenames, train_labels, DESCRIPTOR)\n",
    "test_descriptors, test_labels_descrip = extract_features(\n",
    "    test_images_filenames, test_labels, DESCRIPTOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = np.vstack(train_descriptors)\n",
    "codebook = cluster_local_features(stack, n_clusters=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_histogram(assigned_clusters, num_clusters):\n",
    "    bag_visual_words = np.zeros(\n",
    "        (len(assigned_clusters), num_clusters), dtype=np.float32)\n",
    "    for i in range(len(assigned_clusters)):\n",
    "        hist_i, _ = np.histogram(\n",
    "            assigned_clusters[i], bins=num_clusters, range=(0, num_clusters))\n",
    "        bag_visual_words[i, :] = normalize(hist_i.reshape(1, -1), norm='l2')\n",
    "    return bag_visual_words\n",
    "\n",
    "\n",
    "def obtain_histogram_visual_words(features, tr_lengths=None, codebook=None):\n",
    "    if tr_lengths is None:\n",
    "        tr_lengths = [len(feature) for feature in features]\n",
    "        features = np.vstack(features)\n",
    "    assigned_labels = codebook.predict(features)\n",
    "    lengths = np.array(\n",
    "        [0]+[descriptor_length for descriptor_length in tr_lengths])\n",
    "    lengths = np.cumsum(lengths)\n",
    "    splitted_labels = [assigned_labels[lengths[i]:lengths[i+1]]\n",
    "                       for i in range(len(lengths)-1)]\n",
    "    return compute_histogram(splitted_labels, codebook.cluster_centers_.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words_train = obtain_histogram_visual_words(\n",
    "    train_descriptors, codebook=codebook)\n",
    "visual_words_test = obtain_histogram_visual_words(\n",
    "    test_descriptors, codebook=codebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean', n_jobs=-1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1, metric='euclidean')\n",
    "knn.fit(visual_words_train, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation functions\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "cv_strategies = {\n",
    "    \"kfold\": KFold,\n",
    "    \"stratified\": StratifiedKFold,\n",
    "    \"repeats\": RepeatedStratifiedKFold\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"balanced_accuracy\": balanced_accuracy_score\n",
    "}\n",
    "\n",
    "\n",
    "class BoVWClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" Image classifier using Bag of Visual Words. \"\"\"\n",
    "\n",
    "    def __init__(self, clustering_method, classifier, reduction_method):\n",
    "        self.clustering_method = clustering_method\n",
    "        self.classifier = classifier\n",
    "        self.reduction_method = reduction_method\n",
    "        self.codebook = None\n",
    "\n",
    "    def fit(self, features, labels, sample_weight=None):\n",
    "        tr_lengths = [len(feature) for feature in features]\n",
    "        features = np.vstack(features)\n",
    "        self.codebook = self.clustering_method(features)\n",
    "        tr_hist = obtain_histogram_visual_words(\n",
    "            features, tr_lengths, self.codebook)\n",
    "        tr_hist_reduced = self.reduction_method.fit_transform(tr_hist, labels)\n",
    "        self.classifier.fit(tr_hist_reduced, labels)\n",
    "\n",
    "    def fit_transform(self, features, labels):\n",
    "        self.fit(features, labels)\n",
    "        return self.predict(features)\n",
    "\n",
    "    def predict_proba(self, features):\n",
    "        te_lengths = [len(feature) for feature in features]\n",
    "        features = np.vstack(features)\n",
    "\n",
    "        te_hist = obtain_histogram_visual_words(\n",
    "            features, te_lengths, self.codebook)\n",
    "        te_hist_reduced = self.reduction_method.transform(te_hist)\n",
    "        cls = self.classifier.predict_proba(te_hist_reduced)\n",
    "        return cls\n",
    "\n",
    "    def predict(self, features):\n",
    "        te_lengths = [len(feature) for feature in features]\n",
    "        features = np.vstack(features)\n",
    "\n",
    "        te_hist = obtain_histogram_visual_words(\n",
    "            features, te_lengths, self.codebook)\n",
    "        te_hist_reduced = self.reduction_method.transform(te_hist)\n",
    "        cls = self.classifier.predict(te_hist_reduced)\n",
    "        return cls\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        return (sum(self.predict(X)))\n",
    "\n",
    "    def score_accuracy(self, X, y):\n",
    "        return 100*self.score(X, y)/len(y)\n",
    "\n",
    "\n",
    "class FastCrossValidator:\n",
    "    \"\"\" Cross-validator class \"\"\"\n",
    "\n",
    "    def __init__(self, cv_method, metric_name, trainer, labels):\n",
    "        \"\"\" \n",
    "        Params:\n",
    "        - cv_method (function): Clustering function that when called returns a codebook.\n",
    "        - classifier (Classifier like KNN, LogisticRegression,...)\n",
    "        - reduction_method (None/PCA/LDA/Isomap)\n",
    "        \"\"\"\n",
    "        self.cv_method = cv_method\n",
    "        self.metric_name = metric_name\n",
    "        self.trainer = trainer\n",
    "        self.labels = np.array(labels)\n",
    "\n",
    "    def cross_validate(self, feature_list, labels, n_jobs=-1):\n",
    "        return cross_val_score(self.trainer, feature_list, labels, scoring=self.metric_name, cv=self.cv_method, n_jobs=n_jobs)\n",
    "\n",
    "\n",
    "class Dummy():\n",
    "    \"\"\" Dummy dimensionality reduction method that keeps all the original features. \"\"\"\n",
    "\n",
    "    def fit_transform(self, features, labels):\n",
    "        return features\n",
    "\n",
    "    def transform(self, features):\n",
    "        return features\n",
    "\n",
    "\n",
    "classifiers = {\"KNN\": KNeighborsClassifier}\n",
    "\n",
    "dim_reduction = {\n",
    "    \"None\": Dummy,\n",
    "    \"PCA\": PCA,\n",
    "    \"LDA\": LinearDiscriminantAnalysis,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words_test = obtain_histogram_visual_words(\n",
    "    test_descriptors, codebook=codebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.506815365551425\n"
     ]
    }
   ],
   "source": [
    "accuracy = 100*knn.score(visual_words_test, test_labels)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Dimensonality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.771995043370508\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=64)\n",
    "VWpca = pca.fit_transform(visual_words_train)\n",
    "knnpca = KNeighborsClassifier(n_neighbors=5, n_jobs=-1, metric='euclidean')\n",
    "knnpca.fit(VWpca, train_labels)\n",
    "vwtestpca = pca.transform(visual_words_test)\n",
    "accuracy = 100*knnpca.score(vwtestpca, test_labels)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.267657992565056\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=7)\n",
    "VWlda = lda.fit_transform(visual_words_train, train_labels)\n",
    "knnlda = KNeighborsClassifier(n_neighbors=5, n_jobs=-1, metric='euclidean')\n",
    "knnlda.fit(VWlda, train_labels)\n",
    "vwtestlda = lda.transform(visual_words_test)\n",
    "accuracy = 100*knnlda.score(vwtestlda, test_labels)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.1 \n",
    "● Test different amounts of local features. What performs best?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-30 00:08:02,554]\u001b[0m A new study created in RDB with name: SIFT\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def compare_local_features(trial):\n",
    "    search_metric = \"balanced_accuracy\"\n",
    "    cv_strategy = cv_strategies[\"stratified\"](n_splits=10)\n",
    "    n_features = int(trial.suggest_int('n_features', 50, 1000))\n",
    "    DESCRIPTOR = feature_extractors[\"SIFT\"](n_features=n_features)\n",
    "    train_descriptors, train_labels_descrip = extract_features(\n",
    "        train_images_filenames, train_labels, DESCRIPTOR)\n",
    "    test_descriptors, test_labels_descrip = extract_features(\n",
    "        test_images_filenames, test_labels, DESCRIPTOR)\n",
    "\n",
    "    clustering = partial(cluster_local_features, n_clusters=128)\n",
    "    dim_reduction_type = dim_reduction[\"None\"]()\n",
    "    classifier = classifiers[\"KNN\"](\n",
    "        n_neighbors=5, n_jobs=8, metric='euclidean')\n",
    "\n",
    "    ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "    ex_cv = FastCrossValidator(\n",
    "        cv_strategy, search_metric, ex_trainer, np.unique(train_labels_descrip))\n",
    "    ex_metrics = ex_cv.cross_validate(\n",
    "        train_descriptors, train_labels_descrip, n_jobs=8)\n",
    "\n",
    "    return ex_metrics.mean()\n",
    "\n",
    "\n",
    "# random, grid search all of you want sampler https://optuna.readthedocs.io/en/stable/reference/samplers/index.html\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(\n",
    "    study_name=\"SIFT\", direction='maximize', sampler=sampler, storage=\"sqlite:///bbdd.db\")\n",
    "study.optimize(compare_local_features, n_trials=100,\n",
    "               n_jobs=8, gc_after_trial=True)\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"sift.csv\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.2\n",
    "Use dense SIFT instead of detected keypoints. Conclusions?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_models(trial):\n",
    "    search_metric = \"balanced_accuracy\"\n",
    "    cv_strategy = cv_strategies[\"stratified\"](n_splits=10)\n",
    "    step_size = int(trial.suggest_int('step_size', 2, 100))\n",
    "    patch_size = int(trial.suggest_int('patch_size', 1, 5))\n",
    "    DESCRIPTOR = feature_extractors[\"DenseSIFT\"](\n",
    "        step_size=step_size, patch_size=patch_size)\n",
    "\n",
    "    train_descriptors, train_labels_descrip = extract_features(\n",
    "        train_images_filenames, train_labels, DESCRIPTOR)\n",
    "    test_descriptors, test_labels_descrip = extract_features(\n",
    "        test_images_filenames, test_labels, DESCRIPTOR)\n",
    "\n",
    "    clustering = partial(cluster_local_features, n_clusters=128)\n",
    "    dim_reduction_type = dim_reduction[\"None\"]()\n",
    "    classifier = classifiers[\"KNN\"](\n",
    "        n_neighbors=5, n_jobs=8, metric='euclidean')\n",
    "\n",
    "    ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "    ex_cv = FastCrossValidator(\n",
    "        cv_strategy, search_metric, ex_trainer, np.unique(train_labels_descrip))\n",
    "    ex_metrics = ex_cv.cross_validate(\n",
    "        train_descriptors, train_labels_descrip, n_jobs=8)\n",
    "\n",
    "    return ex_metrics.mean()\n",
    "\n",
    "\n",
    "# random, grid search all of you want sampler https://optuna.readthedocs.io/en/stable/reference/samplers/index.html\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(study_name=\"DenseSIFT\",\n",
    "                            direction='maximize', sampler=sampler, storage=\"sqlite:///bbdd.db\")\n",
    "study.optimize(compare_models, n_trials=100, n_jobs=8, gc_after_trial=True)\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"densesift.csv\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.2\n",
    "● Test different amounts of codebook sizes k. What performs best?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO\n",
    "def compare_n_clusters(trial):\n",
    "    search_metric = \"balanced_accuracy\"\n",
    "    cv_strategy = cv_strategies[\"stratified\"](n_splits=10)\n",
    "\n",
    "    DESCRIPTOR = feature_extractors[\"DenseSIFT\"](\n",
    "        step_size=75, patch_size=3)\n",
    "\n",
    "    n_clusters = int(trial.suggest_categorical(\n",
    "        'n_clusters', [64, 128, 256, 512, 1024]))\n",
    "\n",
    "    train_descriptors, train_labels_descrip = extract_features(\n",
    "        train_images_filenames, train_labels, DESCRIPTOR)\n",
    "    test_descriptors, test_labels_descrip = extract_features(\n",
    "        test_images_filenames, test_labels, DESCRIPTOR)\n",
    "\n",
    "    clustering = partial(cluster_local_features, n_clusters=n_clusters)\n",
    "    dim_reduction_type = dim_reduction[\"None\"]()\n",
    "    classifier = classifiers[\"KNN\"](\n",
    "        n_neighbors=5, n_jobs=8, metric='euclidean')\n",
    "\n",
    "    ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "    ex_cv = FastCrossValidator(\n",
    "        cv_strategy, search_metric, ex_trainer, np.unique(train_labels_descrip))\n",
    "    ex_metrics = ex_cv.cross_validate(\n",
    "        train_descriptors, train_labels_descrip, n_jobs=8)\n",
    "\n",
    "    return ex_metrics.mean()\n",
    "\n",
    "\n",
    "# random, grid search all of you want sampler https://optuna.readthedocs.io/en/stable/reference/samplers/index.html\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(study_name=\"DenseSIFT\",\n",
    "                            direction='maximize', sampler=sampler, storage=\"sqlite:///bbdd.db\")\n",
    "study.optimize(compare_n_clusters, n_trials=100, n_jobs=8, gc_after_trial=True)\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"n_clusters.csv\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.3\n",
    "● Test different values of k for the k-nn classifier. What performs best?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO\n",
    "def compare_k_classifier(trial):\n",
    "    search_metric = \"balanced_accuracy\"\n",
    "    cv_strategy = cv_strategies[\"stratified\"](n_splits=10)\n",
    "\n",
    "    DESCRIPTOR = feature_extractors[\"DenseSIFT\"](\n",
    "        step_size=75, patch_size=3)\n",
    "\n",
    "    n_neighbors = int(trial.init_suggest_int('n_neighbors', 1, 10))\n",
    "\n",
    "    train_descriptors, train_labels_descrip = extract_features(\n",
    "        train_images_filenames, train_labels, DESCRIPTOR)\n",
    "    test_descriptors, test_labels_descrip = extract_features(\n",
    "        test_images_filenames, test_labels, DESCRIPTOR)\n",
    "\n",
    "    clustering = partial(cluster_local_features, n_clusters=256)\n",
    "    dim_reduction_type = dim_reduction[\"None\"]()\n",
    "    classifier = classifiers[\"KNN\"](\n",
    "        n_neighbors=n_neighbors, n_jobs=8, metric='euclidean')\n",
    "\n",
    "    ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "    ex_cv = FastCrossValidator(\n",
    "        cv_strategy, search_metric, ex_trainer, np.unique(train_labels_descrip))\n",
    "    ex_metrics = ex_cv.cross_validate(\n",
    "        train_descriptors, train_labels_descrip, n_jobs=8)\n",
    "\n",
    "    return ex_metrics.mean()\n",
    "\n",
    "\n",
    "# random, grid search all of you want sampler https://optuna.readthedocs.io/en/stable/reference/samplers/index.html\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(\n",
    "    study_name=\"K classifier\", direction='maximize', sampler=sampler, storage=\"sqlite:///bbdd.db\")\n",
    "study.optimize(compare_k_classifier, n_trials=100,\n",
    "               n_jobs=8, gc_after_trial=True)\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"K_classifier.csv\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.4\n",
    "● Test other distances in k-nn classifier. Does that make a difference? Why?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO\n",
    "def compare_distances_classifier(trial):\n",
    "    search_metric = \"balanced_accuracy\"\n",
    "    cv_strategy = cv_strategies[\"stratified\"](n_splits=10)\n",
    "\n",
    "    n_neighbors = int(trial.init_suggest_int('n_neighbors', 1, 10))\n",
    "    metric = trial.suggest_categorical(\n",
    "        'metric', [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"])\n",
    "\n",
    "    DESCRIPTOR = feature_extractors[\"DenseSIFT\"](\n",
    "        step_size=75, patch_size=3)\n",
    "\n",
    "    train_descriptors, train_labels_descrip = extract_features(\n",
    "        train_images_filenames, train_labels, DESCRIPTOR)\n",
    "    test_descriptors, test_labels_descrip = extract_features(\n",
    "        test_images_filenames, test_labels, DESCRIPTOR)\n",
    "\n",
    "    clustering = partial(cluster_local_features, n_clusters=256)\n",
    "    dim_reduction_type = dim_reduction[\"None\"]()\n",
    "    classifier = classifiers[\"KNN\"](\n",
    "        n_neighbors=n_neighbors, n_jobs=8, metric=metric)\n",
    "\n",
    "    ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "    ex_cv = FastCrossValidator(\n",
    "        cv_strategy, search_metric, ex_trainer, np.unique(train_labels_descrip))\n",
    "    ex_metrics = ex_cv.cross_validate(\n",
    "        train_descriptors, train_labels_descrip, n_jobs=8)\n",
    "\n",
    "    return ex_metrics.mean()\n",
    "\n",
    "\n",
    "# random, grid search all of you want sampler https://optuna.readthedocs.io/en/stable/reference/samplers/index.html\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(study_name=\"Distances\",\n",
    "                            direction='maximize', sampler=sampler, storage=\"sqlite:///bbdd.db\")\n",
    "study.optimize(compare_distances_classifier, n_trials=100,\n",
    "               n_jobs=8, gc_after_trial=True)\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"distances.csv\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO\n",
    "def compare_Mix_classifier(trial):\n",
    "    search_metric = \"balanced_accuracy\"\n",
    "    cv_strategy = cv_strategies[\"stratified\"](n_splits=10)\n",
    "    metric = trial.suggest_categorical(\n",
    "        'metric', [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"])\n",
    "\n",
    "    DESCRIPTOR = feature_extractors[\"DenseSIFT\"](\n",
    "        step_size=75, patch_size=3)\n",
    "\n",
    "    train_descriptors, train_labels_descrip = extract_features(\n",
    "        train_images_filenames, train_labels, DESCRIPTOR)\n",
    "    test_descriptors, test_labels_descrip = extract_features(\n",
    "        test_images_filenames, test_labels, DESCRIPTOR)\n",
    "\n",
    "    clustering = partial(cluster_local_features, n_clusters=256)\n",
    "    dim_reduction_type = dim_reduction[\"None\"]()\n",
    "    classifier = classifiers[\"KNN\"](\n",
    "        n_neighbors=5, n_jobs=8, metric=metric)\n",
    "\n",
    "    ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "    ex_cv = FastCrossValidator(\n",
    "        cv_strategy, search_metric, ex_trainer, np.unique(train_labels_descrip))\n",
    "    ex_metrics = ex_cv.cross_validate(\n",
    "        train_descriptors, train_labels_descrip, n_jobs=8)\n",
    "\n",
    "    return ex_metrics.mean()\n",
    "\n",
    "\n",
    "# random, grid search all of you want sampler https://optuna.readthedocs.io/en/stable/reference/samplers/index.html\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(\n",
    "    study_name=\"Mix knn\", direction='maximize', sampler=sampler, storage=\"sqlite:///bbdd.db\")\n",
    "study.optimize(compare_Mix_classifier, n_trials=100,\n",
    "               n_jobs=8, gc_after_trial=True)\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"MIX_KNN.csv\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.5\n",
    "● Play with reducing dimensionality. Conclusions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO\n",
    "def compare_dimensionality(trial):\n",
    "    search_metric = \"balanced_accuracy\"\n",
    "    cv_strategy = cv_strategies[\"stratified\"](n_splits=10)\n",
    "    DESCRIPTOR = feature_extractors[\"DenseSIFT\"](step_size=75, patch_size=3)\n",
    "\n",
    "    train_descriptors, train_labels_descrip = extract_features(\n",
    "        train_images_filenames, train_labels, DESCRIPTOR)\n",
    "    test_descriptors, test_labels_descrip = extract_features(\n",
    "        test_images_filenames, test_labels, DESCRIPTOR)\n",
    "\n",
    "    dimensionality_reduction = trial.suggest_categorical(\n",
    "        'dimensionality_reduction', [\"PCA\", \"LDA\"])\n",
    "\n",
    "    clustering = partial(cluster_local_features, n_clusters=256)\n",
    "    dim_reduction_type = dim_reduction[dimensionality_reduction]()\n",
    "    classifier = classifiers[\"KNN\"](\n",
    "        n_neighbors=5, n_jobs=8, metric='euclidean')\n",
    "\n",
    "    ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "    ex_cv = FastCrossValidator(\n",
    "        cv_strategy, search_metric, ex_trainer, np.unique(train_labels_descrip))\n",
    "    ex_metrics = ex_cv.cross_validate(\n",
    "        train_descriptors, train_labels_descrip, n_jobs=8)\n",
    "\n",
    "    return ex_metrics.mean()\n",
    "\n",
    "\n",
    "# random, grid search all of you want sampler https://optuna.readthedocs.io/en/stable/reference/samplers/index.html\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(\n",
    "    study_name=\"Dimensionality Reduction\", direction='maximize', sampler=sampler, storage=\"sqlite:///bbdd.db\")\n",
    "study.optimize(compare_dimensionality, n_trials=100,\n",
    "               n_jobs=8, gc_after_trial=True)\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"compare_dimensionality.csv\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO BEST MODEL\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 08:28:41) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d50c3de034858aa5bc28c8d16217bb1fee78e4fccfb8e256f6ff5f2e44fbe88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
