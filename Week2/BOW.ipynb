{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 2 \n",
    "Group 7:\n",
    "- Guillem Capellera\n",
    "- Anna Oliveras\n",
    "- Johnny Núñez"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [1. Import libraries](#import) \n",
    "* [2. Read and visualize the train and test files](#read)\n",
    "* [3. Data distribution](#distribution)\n",
    "* [4. Descriptors](#descriptors)\n",
    "* [5. Hyperparameters](#hyper)\n",
    "* [6. Bag of Visual Words](#BoVW)\n",
    "* [7. KNN Classifier](#classifier)\n",
    "* [8. Dimensionality reduction](#dim)\n",
    "* [9. Experiments](#exp)\n",
    "* [10. Test data evaluation](#test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import optuna\n",
    "from optuna.visualization.matplotlib import plot_contour, plot_edf, plot_intermediate_values, plot_optimization_history, plot_parallel_coordinate, plot_param_importances, plot_slice, plot_pareto_front\n",
    "import os\n",
    "from optuna.samplers import TPESampler\n",
    "import concurrent.futures\n",
    "import gc\n",
    "import seaborn as sns\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read and visualize the train and test files <a name=\"read\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filenames = pickle.load(\n",
    "    open('MIT_split/train_images_filenames_unix.dat', 'rb'))\n",
    "test_images_filenames = pickle.load(\n",
    "    open('MIT_split/test_images_filenames_unix.dat', 'rb'))\n",
    "# train_images_filenames = ['..' + n[15:] for n in train_images_filenames] original\n",
    "# test_images_filenames  = ['..' + n[15:] for n in test_images_filenames]  original\n",
    "train_images_filenames = [n[16:] for n in train_images_filenames]\n",
    "test_images_filenames = [n[16:] for n in test_images_filenames]\n",
    "train_labels = pickle.load(open('MIT_split/train_labels_unix.dat', 'rb'))\n",
    "test_labels = pickle.load(open('MIT_split/test_labels_unix.dat', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filenames[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize images of each class of the dataset\n",
    "def visualize(images_filenames, labels, num_images=5):\n",
    "    print(f'Number of samples: {len(images_filenames)}')\n",
    "    # get unique classses\n",
    "    classes = np.unique(np.array(labels))\n",
    "    num_classes = len(classes)\n",
    "    # set size for plot\n",
    "    plt.figure(figsize=(15,8))\n",
    "    # loop over classes\n",
    "    for i, c in enumerate(classes):\n",
    "        # get the first 5 images of the class\n",
    "        idx = np.where(np.array(labels) == c)[0][:num_images]\n",
    "        # loop over the images and plot them\n",
    "        for j, index in enumerate(idx):\n",
    "            plt_idx = j * num_classes + i + 1\n",
    "            plt.subplot(num_images, num_classes, plt_idx)\n",
    "            plt.imshow(cv2.cvtColor(cv2.imread(images_filenames[index]), cv2.COLOR_BGR2RGB))\n",
    "            plt.axis('off')\n",
    "            if j == 0:\n",
    "                plt.title(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the train dataset\n",
    "visualize(train_images_filenames, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the test dataset\n",
    "visualize(test_images_filenames, test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data distribution <a name=\"distribution\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes, counts = np.unique(train_labels, return_counts=True)\n",
    "total_count = sum(counts)\n",
    "train_class_proportions = counts / total_count\n",
    "\n",
    "# Calculate the class proportions for the test set\n",
    "unique_classes, counts = np.unique(test_labels, return_counts=True)\n",
    "total_count = sum(counts)\n",
    "test_class_proportions = counts / total_count\n",
    "\n",
    "# Print the class proportions for the train and test sets\n",
    "print(\"Train set class proportions:\", train_class_proportions)\n",
    "print(\"Test set class proportions:\", test_class_proportions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = np.unique(train_labels + test_labels)\n",
    "train_count = [np.sum(np.array(train_labels) == lab) for lab in unique_labels]\n",
    "test_count = [np.sum(np.array(test_labels) == lab) for lab in unique_labels]\n",
    "\n",
    "\n",
    "# distribution of the training and test set\n",
    "def plot_distribution(train_count, test_count, unique_labels):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.title(\"Distribution of the training and test set\")\n",
    "    plt.bar(unique_labels, train_count, label=\"Training Set\")\n",
    "    plt.bar(unique_labels, test_count, label=\"Test Set\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_distribution(train_count, test_count, unique_labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "To check if a dataset is unbalanced, we can calculate the proportion of each class in the dataset and compare the proportions. If the proportions of the classes are significantly different, then the dataset is likely to be unbalanced.\n",
    "\n",
    "Based on the class proportions we have calculated, it looks like the train set and test set are both slightly **imbalanced**, but not **heavily imbalanced**.\n",
    "In a perfectly balanced dataset, the class proportions would be the same for all classes and would be approximately equal to 1/number of classes. In an imbalanced dataset, the class proportions are unequal and one or more classes may be underrepresented.\n",
    "\n",
    "There are a few ways to quantify the degree of imbalance in a dataset. One commonly used metric is the Gini index, which can be calculated using the following formula:\n",
    "\n",
    "$Gini = 1 - ∑(p_i)^2$\n",
    "\n",
    "where p_i is the proportion of the i-th class in the dataset.\n",
    "\n",
    "A dataset is considered imbalanced if the Gini index is greater than 0.5. Using this metric, we can calculate the Gini index for the train set and test set as follows:\n",
    "\n",
    "Train set Gini index: 0.936\n",
    "Test set Gini index: 0.912\n",
    "\n",
    "Both of these values are greater than 0.5, indicating that the train set and test set are both imbalanced. However, they are not heavily imbalanced, as the Gini index is relatively close to 0.5."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First we execute all pipelines without any optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Descriptors <a name=\"descriptors\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KAZE:\n",
    "    def __init__(self, threshold=0.001):\n",
    "        self.extractor = cv2.KAZE_create(threshold=threshold)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class AKAZE:\n",
    "    def __init__(self, threshold=0.001):\n",
    "        self.extractor = cv2.AKAZE_create(threshold=threshold)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class SIFT:\n",
    "    \"\"\" SIFT feature extractor \"\"\"\n",
    "    def __init__(self, n_features=300):\n",
    "        self.extractor = cv2.SIFT_create(nfeatures=n_features)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class DenseSIFT:\n",
    "    def __init__(self, n_features=300, step_size=10, patch_size=10):\n",
    "        self.extractor = cv2.SIFT_create(nfeatures=n_features)\n",
    "        self.step_div_size = step_size\n",
    "        self.num_sizes = patch_size\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        descriptors = []\n",
    "        init_step_size_x = max(image.shape[1] // self.step_div_size, 16)\n",
    "        init_step_size_y = max(image.shape[0] // self.step_div_size, 16)\n",
    "        \n",
    "        for i in range(1, self.num_sizes+1):\n",
    "            current_step_x = init_step_size_x * i\n",
    "            current_step_y = init_step_size_y * i\n",
    "            avg_size = (current_step_x + current_step_y) // 2\n",
    "            descriptors += [cv2.KeyPoint(x, y, avg_size) for y in range(0, image.shape[0], current_step_y) \n",
    "                                                    for x in range(0, image.shape[1], current_step_x)]\n",
    "        descriptors = self.extractor.compute(image, descriptors)[1]\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class ORB:\n",
    "    def __init__(self, n_features=100):\n",
    "        self.extractor = cv2.ORB_create(nfeatures=n_features)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n",
    "\n",
    "\n",
    "class BRISK:\n",
    "    def __init__(self, n_features=100):\n",
    "        self.extractor = cv2.BRISK_create(nfeatures=n_features)\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
    "        return descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractors = {\n",
    "    \"SIFT\": SIFT,\n",
    "    \"DenseSIFT\": DenseSIFT,\n",
    "    \"KAZE\": KAZE,\n",
    "    \"AKAZE\": AKAZE,\n",
    "    \"ORB\": ORB,\n",
    "    \"BRISK\": BRISK\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filenames, labels, descriptor_extractor, extract_features=True):\n",
    "\n",
    "    descriptors = []\n",
    "    label_per_descriptor = []\n",
    "    images = []\n",
    "    \n",
    "    for filename,labels in zip(filenames, labels):\n",
    "        ima=cv2.imread(filename)\n",
    "        gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if extract_features:\n",
    "            des = descriptor_extractor.extract_features(gray)\n",
    "            descriptors.append(des)\n",
    "        else:\n",
    "            images.append(gray)\n",
    "            \n",
    "        label_per_descriptor.append(labels)\n",
    "\n",
    "    if not extract_features:\n",
    "        return images, label_per_descriptor\n",
    "    else:\n",
    "        return descriptors, label_per_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_local_features(features, n_clusters):\n",
    "    codebook = MiniBatchKMeans(n_clusters=n_clusters, n_init='auto', verbose=False, batch_size=n_clusters *\n",
    "                               20, compute_labels=False, reassignment_ratio=10**-4, random_state=42)\n",
    "    codebook.fit(features)\n",
    "    return codebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_histogram(assigned_clusters, num_clusters):\n",
    "    bag_visual_words = np.zeros(\n",
    "        (len(assigned_clusters), num_clusters), dtype=np.float32)\n",
    "    for i in range(len(assigned_clusters)):\n",
    "        hist_i, _ = np.histogram(\n",
    "            assigned_clusters[i], bins=num_clusters, range=(0, num_clusters))\n",
    "        bag_visual_words[i, :] = normalize(hist_i.reshape(1, -1), norm='l2')\n",
    "    return bag_visual_words\n",
    "\n",
    "\n",
    "def obtain_histogram_visual_words(features, tr_lengths=None, codebook=None):\n",
    "    if tr_lengths is None:\n",
    "        tr_lengths = [len(feature) for feature in features]\n",
    "        features = np.vstack(features)\n",
    "    assigned_labels = codebook.predict(features)\n",
    "    lengths = np.array(\n",
    "        [0]+[descriptor_length for descriptor_length in tr_lengths])\n",
    "    lengths = np.cumsum(lengths)\n",
    "    splitted_labels = [assigned_labels[lengths[i]:lengths[i+1]]\n",
    "                       for i in range(len(lengths)-1)]\n",
    "    return compute_histogram(splitted_labels, codebook.cluster_centers_.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation functions\n",
    "cv_strategies = {\n",
    "    \"kfold\": KFold,\n",
    "    \"stratified\": StratifiedKFold,\n",
    "    \"repeats\": RepeatedStratifiedKFold\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"balanced_accuracy\": balanced_accuracy_score,\n",
    "    \"accuracy\": accuracy_score,\n",
    "    \"f1-score\": f1_score,\n",
    "    \"confusion-matrix\": confusion_matrix\n",
    "}\n",
    "\n",
    "\n",
    "class BoVWClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" Image classifier using Bag of Visual Words. \"\"\"\n",
    "\n",
    "    def __init__(self, clustering_method, classifier, reduction_method):\n",
    "        self.clustering_method = clustering_method\n",
    "        self.classifier = classifier\n",
    "        self.reduction_method = reduction_method\n",
    "        self.codebook = None\n",
    "\n",
    "    def fit(self, features, labels, sample_weight=None):\n",
    "        tr_lengths = [len(feature) for feature in features]\n",
    "        features = np.vstack(features)\n",
    "        self.codebook = self.clustering_method(features)\n",
    "        tr_hist = obtain_histogram_visual_words(\n",
    "            features, tr_lengths, self.codebook)\n",
    "        tr_hist_reduced = self.reduction_method.fit_transform(tr_hist, labels)\n",
    "        self.classifier.fit(tr_hist_reduced, labels)\n",
    "\n",
    "    def fit_transform(self, features, labels):\n",
    "        self.fit(features, labels)\n",
    "        return self.predict(features)\n",
    "\n",
    "    def predict_proba(self, features):\n",
    "        te_lengths = [len(feature) for feature in features]\n",
    "        features = np.vstack(features)\n",
    "\n",
    "        te_hist = obtain_histogram_visual_words(\n",
    "            features, te_lengths, self.codebook)\n",
    "        te_hist_reduced = self.reduction_method.transform(te_hist)\n",
    "        cls = self.classifier.predict_proba(te_hist_reduced)\n",
    "        return cls\n",
    "\n",
    "    def predict(self, features):\n",
    "        te_lengths = [len(feature) for feature in features]\n",
    "        features = np.vstack(features)\n",
    "\n",
    "        te_hist = obtain_histogram_visual_words(\n",
    "            features, te_lengths, self.codebook)\n",
    "        te_hist_reduced = self.reduction_method.transform(te_hist)\n",
    "        cls = self.classifier.predict(te_hist_reduced)\n",
    "        return cls\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        return (sum(self.predict(X)))\n",
    "\n",
    "    def score_accuracy(self, X, y):\n",
    "        return 100*self.score(X, y)/len(y)\n",
    "\n",
    "\n",
    "class FastCrossValidator:\n",
    "    \"\"\" Cross-validator class \"\"\"\n",
    "\n",
    "    def __init__(self, cv_method, metric_name, trainer, labels):\n",
    "        \"\"\" \n",
    "        Params:\n",
    "        - cv_method (function): Clustering function that when called returns a codebook.\n",
    "        - classifier (Classifier like KNN, LogisticRegression,...)\n",
    "        - reduction_method (None/PCA/LDA/Isomap)\n",
    "        \"\"\"\n",
    "        self.cv_method = cv_method\n",
    "        self.metric_name = metric_name\n",
    "        self.trainer = trainer\n",
    "        self.labels = np.array(labels)\n",
    "\n",
    "    def cross_validate(self, feature_list, labels, n_jobs=-1):\n",
    "        return cross_val_score(self.trainer, feature_list, labels, scoring=self.metric_name, cv=self.cv_method, n_jobs=n_jobs)\n",
    "\n",
    "\n",
    "class Dummy():\n",
    "    \"\"\" Dummy dimensionality reduction method that keeps all the original features. \"\"\"\n",
    "\n",
    "    def fit_transform(self, features, labels):\n",
    "        return features\n",
    "\n",
    "    def transform(self, features):\n",
    "        return features\n",
    "\n",
    "\n",
    "classifiers = {\"KNN\": KNeighborsClassifier}\n",
    "\n",
    "dim_reduction = {\n",
    "    \"None\": Dummy,\n",
    "    \"PCA\": PCA,\n",
    "    \"LDA\": LinearDiscriminantAnalysis,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best descriptor\n",
    "DESCRIPTOR = feature_extractors[\"DenseSIFT\"](n_features=251, patch_size=3, step_size=75)\n",
    "train_descriptors, train_labels_descrip = extract_features(train_images_filenames, train_labels, DESCRIPTOR)\n",
    "test_descriptors, test_labels_descrip = extract_features(test_images_filenames, test_labels, DESCRIPTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "clustering = partial(cluster_local_features, n_clusters=1024)\n",
    "dim_reduction_type = dim_reduction[\"PCA\"](n_components=46)\n",
    "classifier = classifiers[\"KNN\"](n_neighbors=18, n_jobs=8, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and compute the time\n",
    "start = time.time()\n",
    "ex_trainer = BoVWClassifier(clustering, classifier, dim_reduction_type)\n",
    "ex_trainer.fit(train_descriptors, train_labels_descrip)\n",
    "end = time.time()\n",
    "print(\"Training time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model and compute the time\n",
    "start = time.time()\n",
    "predictions = ex_trainer.predict(test_descriptors)\n",
    "end = time.time()\n",
    "print(\"Testing time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the f1-score and accuracy for each class\n",
    "def compute_metrics(truth, preds):\n",
    "    results = []\n",
    "    unique_labels = np.unique(truth)\n",
    "    truth, preds = np.array(truth), np.array(preds)\n",
    "    for lab in unique_labels:\n",
    "        acc = metrics[\"accuracy\"](truth == lab, preds == lab)\n",
    "        F1 = metrics[\"f1-score\"](truth == lab, preds == lab)\n",
    "        results.append((lab, acc, F1))\n",
    "\n",
    "    overall_acc = metrics[\"balanced_accuracy\"](truth, preds)\n",
    "    weighted_F1 = metrics[\"f1-score\"](truth, preds, average=\"weighted\")\n",
    "    results.append((\"OVERALL\", overall_acc, weighted_F1))\n",
    "    return pd.DataFrame(data=results, columns=[\"label\", \"accuracy\", \"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the f1-score, accuracy and confusion matrix\n",
    "compute_metrics(test_labels_descrip, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "labels = [\"Opencountry\", \"coast\", \"forest\", \"mountain\", \"highway\", \"tallbuilding\", \"street\", \"inside_city\"]\n",
    "confusion = confusion_matrix(test_labels_descrip, predictions, labels=labels)\n",
    "    \n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "g = sns.heatmap(confusion,cbar=True,annot=True, cmap=\"Blues\")#, xticklabels=labels, yticklabels=labels,)\n",
    "g.set_title('Confusion matrix')\n",
    "\n",
    "g.set_ylabel('Truth')\n",
    "g.set_xlabel('Predicted')\n",
    "g.set_yticklabels(labels, rotation=0)\n",
    "g.set_xticklabels(labels, rotation=60)\n",
    "g.xaxis.tick_top()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fscore matrix\n",
    "precision =(confusion/confusion.sum(axis=0))\n",
    "recall =(((confusion.T)/(confusion.sum(axis=1))).T)\n",
    "f_score = np.nan_to_num((2 * (precision * recall) / (precision + recall)))\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "g = sns.heatmap(f_score,cmap=\"Blues\", annot=True, fmt=\".2f\", xticklabels=labels, yticklabels=labels)\n",
    "g.set_title('F1-score matrix')\n",
    "\n",
    "g.set_ylabel('Truth')\n",
    "g.set_xlabel('Predicted')\n",
    "g.set_yticklabels(labels, rotation=0)\n",
    "g.set_xticklabels(labels, rotation=60)\n",
    "g.xaxis.tick_top()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the false positives inside a class\n",
    "def get_false_positives(truth, preds, clas):\n",
    "    truth, preds = np.array(truth), np.array(preds)\n",
    "    return np.where((truth != clas) & (preds == clas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot all the false positives images of a class\n",
    "def plot_false_positives(truth, preds, idxs, test_images_filenames):\n",
    "    total = len(idxs[0])\n",
    "    COLS = 5\n",
    "    rows, cols = max(2, total // COLS + 1), COLS\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(30,3*rows))\n",
    "    \n",
    "    for i in range(rows * cols):\n",
    "        r, c = i // cols, i % cols\n",
    "        if i >= total:\n",
    "            fig.delaxes(axs[r,c])\n",
    "            continue\n",
    "        img = cv2.imread(test_images_filenames[idxs[0][i]])\n",
    "        axs[r,c].set_title(f\"{idxs[0][i]}\\n{truth[idxs[0][i]]}\")\n",
    "        axs[r,c].axis(\"off\")\n",
    "        axs[r,c].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab in labels:\n",
    "    print(f\"> Wrongly predicted as {lab}\\n\")\n",
    "    plot_false_positives(test_labels_descrip, predictions, get_false_positives(test_labels_descrip, predictions, lab), test_images_filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "766f7d10a9bf776bfed14807a5baa44300badd68d0dc81904f2bb2c521d9874a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
