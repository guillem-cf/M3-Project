2023-01-19 17:24:36.526534: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-19 17:24:37.348569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/cuda/lib64
2023-01-19 17:24:37.348675: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/cuda/lib64
2023-01-19 17:24:37.348686: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
wandb: Currently logged in as: guillemcafo (grup7). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /export/home/group07/M3_Project/Week3/wandb/run-20230119_172440-dxqv3w2g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run baseline
wandb: ⭐️ View project at https://wandb.ai/grup7/M3
wandb: 🚀 View run at https://wandb.ai/grup7/M3/runs/dxqv3w2g
2023-01-19 17:24:47.226516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-19 17:24:47.885197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22293 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6
wandb: WARNING The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2023-01-19 17:24:49.708249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-01-19 17:24:49.712525: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fb5a400f7e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-01-19 17:24:49.712565: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-01-19 17:24:49.718505: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-01-19 17:24:49.905419: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
wandb: Adding directory to artifact (/export/home/group07/M3_Project/Week3/wandb/run-20230119_172440-dxqv3w2g/files/model-best)... Done. 0.2s
wandb: Adding directory to artifact (/export/home/group07/M3_Project/Week3/wandb/run-20230119_172440-dxqv3w2g/files/model-best)... Done. 0.3s
wandb: Adding directory to artifact (/export/home/group07/M3_Project/Week3/wandb/run-20230119_172440-dxqv3w2g/files/model-best)... Done. 0.2s
wandb: Adding directory to artifact (/export/home/group07/M3_Project/Week3/wandb/run-20230119_172440-dxqv3w2g/files/model-best)... Done. 0.3s
wandb: Adding directory to artifact (/export/home/group07/M3_Project/Week3/wandb/run-20230119_172440-dxqv3w2g/files/model-best)... Done. 0.4s
wandb: Adding directory to artifact (/export/home/group07/M3_Project/Week3/wandb/run-20230119_172440-dxqv3w2g/files/model-best)... Done. 0.2s
wandb: Adding directory to artifact (/export/home/group07/M3_Project/Week3/wandb/run-20230119_172440-dxqv3w2g/files/model-best)... Done. 0.3s
wandb: Adding directory to artifact (/export/home/group07/M3_Project/Week3/wandb/run-20230119_172440-dxqv3w2g/files/model-best)... Done. 0.3s
wandb: Adding directory to artifact (/export/home/group07/M3_Project/Week3/wandb/run-20230119_172440-dxqv3w2g/files/model-best)... Done. 0.5s
wandb: Adding directory to artifact (/export/home/group07/M3_Project/Week3/wandb/run-20230119_172440-dxqv3w2g/files/model-best)... Done. 0.3s
Traceback (most recent call last):
  File "/export/home/group07/M3_Project/Week3/mlp_MIT_8_scene.py", line 150, in <module>
    model.save_weights(args.MODEL_FNAME)  # always save your weights after training or during training
  File "/ghome/group07/anaconda3/envs/m3/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/ghome/group07/anaconda3/envs/m3/lib/python3.10/site-packages/h5py/_hl/files.py", line 533, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)
  File "/ghome/group07/anaconda3/envs/m3/lib/python3.10/site-packages/h5py/_hl/files.py", line 232, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 126, in h5py.h5f.create
FileNotFoundError: [Errno 2] Unable to create file (unable to open file: name = './model/patch_based_mlp.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: 
wandb: Run history:
wandb:     accuracy ▁▂▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████
wandb:        epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:         loss █▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: val_accuracy ▁▃▄▃▄▄▅▆▆▅▅▆▄▆▆▇▆▇▆▇▇▆▇▇▇▇▇█▇▇▇▇▇▇█▇██▆▇
wandb:     val_loss █▇▅▅▅▄▃▂▂▄▄▂▅▃▁▂▃▂▂▂▂▃▂▁▁▂▁▁▃▂▂▃▃▄▃▃▃▂▆▃
wandb: 
wandb: Run summary:
wandb:      accuracy 0.91206
wandb:    best_epoch 19
wandb: best_val_loss 1.16771
wandb:         epoch 49
wandb:          loss 0.27478
wandb:  val_accuracy 0.5925
wandb:      val_loss 1.37404
wandb: 
wandb: 🚀 View run baseline at: https://wandb.ai/grup7/M3/runs/dxqv3w2g
wandb: Synced 6 W&B file(s), 0 media file(s), 52 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230119_172440-dxqv3w2g/logs
