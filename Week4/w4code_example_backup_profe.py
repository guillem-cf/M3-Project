from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras import backend as K
from tensorflow.keras.utils import plot_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import TensorBoard
import matplotlib

matplotlib.use("Agg")
import matplotlib.pyplot as plt


train_data_dir = "/ghome/mcv/datasets/MIT_split/train"
val_data_dir = "/ghome/mcv/datasets/MIT_split/test"
test_data_dir = "/ghome/mcv/datasets/MIT_split/test"
img_width = 224
img_height = 224
batch_size = 32
number_of_epoch = 2
validation_samples = 807


def preprocess_input(x, dim_ordering="default"):
    if dim_ordering == "default":
        dim_ordering = K.image_data_format()
    assert dim_ordering in {"channels_first", "channels_last"}

    if dim_ordering == "channels_first":
        # 'RGB'->'BGR'
        x = x[::-1, :, :]
        # Zero-center by mean pixel
        x[0, :, :] -= 103.939
        x[1, :, :] -= 116.779
        x[2, :, :] -= 123.68
    else:
        # 'RGB'->'BGR'
        x = x[:, :, ::-1]
        # Zero-center by mean pixel
        x[:, :, 0] -= 103.939
        x[:, :, 1] -= 116.779
        x[:, :, 2] -= 123.68
    return x


# create the base pre-trained model
base_model = VGG16(weights="imagenet")
plot_model(base_model, to_file="modelVGG16a.png", show_shapes=True, show_layer_names=True)

x = base_model.layers[-2].output
x = Dense(8, activation="softmax", name="predictions")(x)

model = Model(inputs=base_model.input, outputs=x)
plot_model(model, to_file="modelVGG16b.png", show_shapes=True, show_layer_names=True)
for layer in base_model.layers:
    layer.trainable = False


model.compile(loss="categorical_crossentropy", optimizer="adadelta", metrics=["accuracy"])
for layer in model.layers:
    print(layer.name, layer.trainable)

# preprocessing_function=preprocess_input,
datagen = ImageDataGenerator(
    featurewise_center=False,
    samplewise_center=False,
    featurewise_std_normalization=False,
    samplewise_std_normalization=False,
    preprocessing_function=preprocess_input,
    rotation_range=0.0,
    width_shift_range=0.0,
    height_shift_range=0.0,
    shear_range=0.0,
    zoom_range=0.0,
    channel_shift_range=0.0,
    fill_mode="nearest",
    cval=0.0,
    horizontal_flip=False,
    vertical_flip=False,
    rescale=None,
)

train_generator = datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode="categorical",
)

test_generator = datagen.flow_from_directory(
    test_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode="categorical",
)

validation_generator = datagen.flow_from_directory(
    val_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode="categorical",
)

history = model.fit(
    train_generator,
    steps_per_epoch=(int(400 // batch_size) + 1),
    epochs=number_of_epoch,
    validation_data=validation_generator,
    validation_steps=(int(validation_samples // batch_size) + 1),
    callbacks=[],
)


result = model.evaluate(test_generator)
print(result)
print(history.history.keys())


# list all data in history

if True:
    # summarize history for accuracy
    plt.plot(history.history["accuracy"])
    plt.plot(history.history["val_accuracy"])
    plt.title("model accuracy")
    plt.ylabel("accuracy")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.savefig("accuracy.jpg")
    plt.close()
    # summarize history for loss
    plt.plot(history.history["loss"])
    plt.plot(history.history["val_loss"])
    plt.title("model loss")
    plt.ylabel("loss")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.savefig("loss.jpg")
